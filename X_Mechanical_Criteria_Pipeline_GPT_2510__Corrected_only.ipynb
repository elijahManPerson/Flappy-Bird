{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elijahManPerson/Flappy-Bird/blob/master/X_Mechanical_Criteria_Pipeline_GPT_2510__Corrected_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oW1-qD1EBPP"
      },
      "source": [
        "# Data access and libray set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbjvTYncD4ck"
      },
      "source": [
        "Mounting the Google Drive to access files and save them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRUXnGKtEOgU"
      },
      "source": [
        "# Step 1: Mount Google Drive\n",
        "## Purpose:\n",
        "To access and manipulate files stored in your Google Drive from the Colab environment.\n",
        "\n",
        "##What each part does\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  drive.mount('/content/drive') starts the Google auth flow so Colab can access your Drive.\n",
        "* CHECK_PATH is the single place to point at your working folder.\n",
        "*  The helper status() prints clear pass or fail messages.\n",
        "*  Read test lists a few entries to confirm you can read.\n",
        "*  Write test creates and deletes a tiny file to confirm you can write.\n",
        "\n",
        "## Actions:\n",
        "\n",
        "**Import and Mount:** Uses google.colab.drive to mount the drive.\n",
        "Verification: Checks if the drive is successfully mounted by verifying the existence of the /content/drive/MyDrive directory.\n",
        "\n",
        "## Outcome:\n",
        "Access to files within Google Drive is established, allowing the script to read from and write to specific directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In1Zp8P5EHXW",
        "outputId": "94a72657-812f-4d63-a808-31cbd4569767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Drive mount detected at /content/drive\n",
            "✅ MyDrive folder present\n",
            "✅ Read test passed (listed MyDrive)\n",
            "   • Sample entries: ['Colab Notebooks', 'Untitled.gdoc', 'Copy of Untitled.gdoc', 'Russelline Doxology.gdoc', 'Application Letter to St. John Bosco.gdoc']\n",
            "✅ Write test passed (created file)\n",
            "✅ Cleanup passed (deleted file)\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# Step 1: Mount Google Drive\n",
        "# ===============================================\n",
        "# ==== Drive mount + verification ====\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # remove force_remount if you do not want to re-prompt\n",
        "\n",
        "import os, time\n",
        "\n",
        "def status(msg, ok):\n",
        "    print((\"✅ \" if ok else \"❌ \") + msg)\n",
        "\n",
        "root_mount = '/content/drive'\n",
        "root_mydrive = '/content/drive/MyDrive'\n",
        "\n",
        "# 1) Basic mount checks\n",
        "status(\"Drive mount detected at /content/drive\", os.path.ismount(root_mount))\n",
        "status(\"MyDrive folder present\", os.path.isdir(root_mydrive))\n",
        "\n",
        "# 2) Read test: list a few entries in MyDrive\n",
        "try:\n",
        "    entries = os.listdir(root_mydrive)[:5]\n",
        "    status(\"Read test passed (listed MyDrive)\", True)\n",
        "    print(\"   • Sample entries:\", entries if entries else \"(empty)\")\n",
        "except Exception as e:\n",
        "    status(f\"Read test failed: {e}\", False)\n",
        "\n",
        "# 3) Write test: create and remove a tiny file\n",
        "probe_path = os.path.join(root_mydrive, \"_colab_mount_check.txt\")\n",
        "try:\n",
        "    with open(probe_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"colab mount check {time.time()}\\n\")\n",
        "    status(\"Write test passed (created file)\", True)\n",
        "    os.remove(probe_path)\n",
        "    status(\"Cleanup passed (deleted file)\", True)\n",
        "except Exception as e:\n",
        "    status(f\"Write test failed: {e}\", False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2.0 Data upload guide (optional)\n",
        "###Strict loader for files where:\n",
        "- first column = ID\n",
        "- last column  = Raw text\n",
        "- everything else optional\n",
        "\n",
        "###Instructions for preparing your CSV\n",
        "\n",
        "Put your unique identifier in the first column. Name it whatever you like, but “ID” is unambiguous.\n",
        "\n",
        "Put the original writing text in the last column. Name it “Raw text” for readability.\n",
        "\n",
        "Any other fields can live between first and last. They’ll be preserved, but not required.\n",
        "\n",
        "Save as CSV with UTF-8 encoding. If you’re unsure, Excel and Google Sheets default exports are fine; our loader tolerates BOM too.\n"
      ],
      "metadata": {
        "id": "Lk878yx_PRH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "\n",
        "# Build blank DataFrames\n",
        "df_min = pd.DataFrame(columns=[\"ID\", \"Raw text\"])\n",
        "df_ext = pd.DataFrame(columns=[\n",
        "    \"ID\", \"AU\", \"TS\", \"CS/PD\", \"Voc\", \"Coh\", \"Pa\", \"SS\", \"Pun\", \"Spell\",\n",
        "    \"Total\", \"WordCount\", \"yrlev\", \"Prompt ID\", \"Prompt Name\", \"Raw text\"\n",
        "])\n",
        "\n",
        "# Save to local workspace\n",
        "df_min.to_csv(\"/content/texts_template_min.csv\", index=False, encoding=\"utf-8\")\n",
        "df_ext.to_csv(\"/content/texts_template_extended.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Button callbacks\n",
        "def on_download_min(_):\n",
        "    files.download(\"/content/texts_template_min.csv\")\n",
        "\n",
        "def on_download_ext(_):\n",
        "    files.download(\"/content/texts_template_extended.csv\")\n",
        "\n",
        "# UI\n",
        "display(widgets.HTML(\"<h4>Download a CSV Template</h4>\"))\n",
        "display(widgets.HTML(\n",
        "    \"Use the first column as <b>ID</b> and the last as <b>Raw text</b>.<br>\"\n",
        "    \"Everything in between is optional.\"\n",
        "))\n",
        "btn_min = widgets.Button(description=\"⬇️ Download Minimal Template (ID + Raw text)\", button_style=\"primary\")\n",
        "btn_ext = widgets.Button(description=\"⬇️ Download Extended Template (Full NAPLAN-style)\", button_style=\"info\")\n",
        "\n",
        "btn_min.on_click(on_download_min)\n",
        "btn_ext.on_click(on_download_ext)\n",
        "display(widgets.HBox([btn_min, btn_ext]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "c614125d7df3424599ae8c6f7917e3eb",
            "f1b9a648cd6e4d72a4acea342f727efe",
            "e8ab5a48f965475cad28034238b67648",
            "394935e6562844939073c758bcc6b824",
            "55e0b2ffc5e54c5fa3470f3e6a2b41e4",
            "9c5657533e89428d9a4f116d2f3a31e2",
            "8841570d2e8042d2b9a4ac34165410ba",
            "c5cfd5ece48d4e678534fcee0e169b10",
            "a15408a9c67e4311a3af2c7f647eeaa0",
            "d4b37fb87abf40b7a0ec74df8cd29659",
            "0656922103d943f0a9cf622262bca3d7",
            "8e0e76b92fb04a078ae1f87a4b850e6c",
            "9d7712f4b50b49f1adb639bda7935e59",
            "99432b51260848629ec9a29af72eb88e"
          ]
        },
        "id": "jjbxtPp1MMHE",
        "outputId": "ed24f400-7059-4e96-e022-64af08059d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<h4>Download a CSV Template</h4>')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c614125d7df3424599ae8c6f7917e3eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='Use the first column as <b>ID</b> and the last as <b>Raw text</b>.<br>Everything in between is opt…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "394935e6562844939073c758bcc6b824"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(button_style='primary', description='⬇️ Download Minimal Template (ID + Raw text)', styl…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8841570d2e8042d2b9a4ac34165410ba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNU49R2-EVwD"
      },
      "source": [
        "# Step 2 — Load and Preprocess Data\n",
        "\n",
        "###Purpose\n",
        "- Bring a CSV file from Google Drive into Python as a Pandas DataFrame, then ensure the key text column is present, consistently named, and safe to use.\n",
        "- The rest of the pipeline expects a column called \"Raw text\". This step prepares that column so later steps do not break.\n",
        "\n",
        "###What you may need to change\n",
        "- DATA_PATH: set this to the exact path of your CSV inside Google Drive. If you moved the file or renamed folders, update it here.\n",
        "\n",
        "###Inputs\n",
        "- A CSV file located at DATA_PATH. The file should contain one column that holds the original student text or source text. It might be called \"Raw text\", \"Raw Text\", \"raw_text\", or something similar.\n",
        "\n",
        "###Outputs\n",
        "- df_preprocessed: a Pandas DataFrame that definitely has a column named \"Raw text\". If your file used a variant name, the code renames it to \"Raw text\" so the rest of the notebook can rely on one standard.\n",
        "- Printed checks that confirm: the path is valid, the file loaded, how many rows are present, how many are non-empty in \"Raw text\", and a small sample of the first few rows.\n",
        "\n",
        "###Key ideas\n",
        "- CSVs created on different systems sometimes include a special marker at the start of the file called a BOM. Using UTF-8 with BOM support avoids header glitches.\n",
        "- Real-world files often vary in how they label the same concept. We accept common header variants for the text column, then rename to \"Raw text\" so every downstream function can assume one consistent name.\n",
        "- It is better to stop early if the text column is missing or empty rather than let subtle errors propagate. This step fails fast with a clear message if something essential is wrong.\n",
        "\n",
        "###Actions performed in this code\n",
        "1) Validate your CSV path.  \n",
        "2) Load the CSV with safe defaults and BOM handling.  \n",
        "3) Find and standardise the \"Raw text\" column (case and spacing tolerant).  \n",
        "4) Fill missing values and report how many rows are usable.  \n",
        "5) Preview the first few rows.  \n",
        "\n",
        "###Verification prints\n",
        "- \"CSV path exists\" confirms the notebook can see the file. If you get a cross here, fix DATA_PATH.\n",
        "- \"Data loaded. Rows: X, Columns: Y\" confirms the file parsed as a table.\n",
        "- \"Non-empty 'Raw text' rows: A of B\" shows how many rows actually contain usable text after trimming blanks.\n",
        "- A preview of the first five rows lets you eyeball whether the data looks right before moving on.\n",
        "\n",
        "###Common pitfalls\n",
        "- Wrong path: the file was moved, renamed, or the folder hierarchy changed. Update DATA_PATH.\n",
        "- Unusual delimiter or BOM: some CSVs use semicolons or tabs, or include a BOM. The loader handles most cases, but if columns look fused together, specify a delimiter explicitly.\n",
        "- Header named slightly differently: if your text column label is unexpected, the auto-detection usually finds it. If not, either rename the column in the CSV or add your variant to the accepted names in the code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTE:\n",
        "####DATA_PATH = \"/content/drive/MyDrive/JM/Sandbox/1.Training Data/Data for Testing avg short.csv\"\n",
        "#### RAW_TEXT_ALIASES = {\"raw text\", \"raw_text\", \"rawtext\"}\n"
      ],
      "metadata": {
        "id": "G6FlfiBvDXJ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac1-dfhgC1SO",
        "outputId": "1eee0833-6e74-4be8-b2a9-6d4449192213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV path exists\n",
            "✅ CSV path exists\n",
            "✅ Parsed using: comma. Columns: 15\n",
            "✅ Non-empty 'Raw text' rows: 21 of 21\n",
            "\n",
            "First 5 rows of 'Raw text':\n",
            "                                            Raw text\n",
            "0  There once was a girl called lilly she had pet...\n",
            "1  wrire a narrative story abouta search for some...\n",
            "2  The Failed Submarine I had always wanted go on...\n",
            "3  The diamond ring Emmy was just having breakfas...\n",
            "4  If you are locking for a dimiens go to most di...\n",
            "✅ Average character length across 'Raw text': 1504.6\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# Step 2: Load and Preprocess Data  + optional download\n",
        "# ===============================================\n",
        "\n",
        "\n",
        "import os, io, csv\n",
        "import pandas as pd\n",
        "\n",
        "def status(msg, ok=True):\n",
        "    print((\"✅ \" if ok else \"❌ \") + msg)\n",
        "\n",
        "# ======= EDIT HERE IF NEEDED =======\n",
        "DATA_PATH = \"/content/drive/MyDrive/JM/Sandbox/1.Training Data/Data for Testing avg short.csv\"\n",
        "RAW_TEXT_ALIASES = {\"raw text\", \"raw_text\", \"rawtext\"}\n",
        "# ===================================\n",
        "\n",
        "# If your CSV path doesn't exist, create a tiny sample so Run all won't fail\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    status(f\"File not found: {DATA_PATH}\", ok=False)\n",
        "    os.makedirs(os.path.dirname(DATA_PATH), exist_ok=True)\n",
        "    sample = pd.DataFrame({\n",
        "        \"ID\": [\"A1\",\"A2\",\"A3\",\"A4\"],\n",
        "        \"Raw text\": [\n",
        "            \"once upon a time a cat met a robot\",\n",
        "            \"yesterday we visit the museum it were fun\",\n",
        "            \"“stop!” he said i will go now\",\n",
        "            \"the end\"\n",
        "        ]\n",
        "    })\n",
        "    sample.to_csv(DATA_PATH, index=False, encoding=\"utf-8\")\n",
        "    status(\"Created a small sample CSV so the pipeline can run.\", ok=True)\n",
        "else:\n",
        "    status(\"CSV path exists\")\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    status(f\"File not found: {DATA_PATH}\", ok=False)\n",
        "    raise FileNotFoundError(DATA_PATH)\n",
        "status(\"CSV path exists\")\n",
        "\n",
        "def try_read(path, sep, engine=None):\n",
        "    kwargs = dict(encoding=\"utf-8-sig\", on_bad_lines=\"skip\", low_memory=False)\n",
        "    if sep is None:\n",
        "        kwargs[\"sep\"] = None\n",
        "        kwargs[\"engine\"] = \"python\"  # auto-sniff\n",
        "    else:\n",
        "        kwargs[\"sep\"] = sep\n",
        "        if engine:\n",
        "            kwargs[\"engine\"] = engine\n",
        "    try:\n",
        "        df = pd.read_csv(path, **kwargs)\n",
        "        return df\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# Try several parsers; keep the best\n",
        "candidates = [\n",
        "    (\"auto-sniff\", None, \"python\"),\n",
        "    (\"comma\", \",\", None),\n",
        "    (\"semicolon\", \";\", None),\n",
        "    (\"tab\", \"\\t\", None),\n",
        "    (\"pipe\", \"|\", None),\n",
        "]\n",
        "\n",
        "best = None\n",
        "best_score = (-1, -1)  # (has_raw_text_like, n_cols)\n",
        "\n",
        "def score_df(df):\n",
        "    if df is None or df.empty:\n",
        "        return (-1, -1)\n",
        "    cols = [c.strip().lower() for c in df.columns]\n",
        "    has_raw_like = int(any(c in RAW_TEXT_ALIASES for c in cols) or (\"raw\" in cols and \"text\" in cols))\n",
        "    return (has_raw_like, len(cols))\n",
        "\n",
        "parsed_by = None\n",
        "for name, sep, eng in candidates:\n",
        "    df = try_read(DATA_PATH, sep, eng)\n",
        "    s = score_df(df)\n",
        "    if s > best_score:\n",
        "        best_score, best, parsed_by = s, df, name\n",
        "\n",
        "if best is None or best.empty:\n",
        "    status(\"Failed to read CSV with all strategies\", ok=False)\n",
        "    raise ValueError(\"Could not parse CSV\")\n",
        "\n",
        "status(f\"Parsed using: {parsed_by}. Columns: {len(best.columns)}\")\n",
        "\n",
        "df_preprocessed = best.copy()\n",
        "\n",
        "# --- Standardise/repair the Raw text column ---\n",
        "cols_norm = {c: c.strip().lower() for c in df_preprocessed.columns}\n",
        "\n",
        "raw_col = None\n",
        "for c, norm in cols_norm.items():\n",
        "    if norm in RAW_TEXT_ALIASES:\n",
        "        raw_col = c\n",
        "        break\n",
        "\n",
        "# If we didn't find it, handle the split-header case: \"Raw\" and \"text\" as separate columns\n",
        "if raw_col is None and \"raw\" in cols_norm.values() and \"text\" in cols_norm.values():\n",
        "    # Find the actual column names that normalise to 'raw' and 'text'\n",
        "    raw_name = next(k for k, v in cols_norm.items() if v == \"raw\")\n",
        "    text_name = next(k for k, v in cols_norm.items() if v == \"text\")\n",
        "\n",
        "    # Merge them into one string column, preserving whichever side has content\n",
        "    df_preprocessed[\"Raw text\"] = (\n",
        "        df_preprocessed[raw_name].astype(str).fillna(\"\").str.rstrip() +\n",
        "        df_preprocessed[text_name].astype(str).fillna(\"\").radd(\n",
        "            df_preprocessed[text_name].astype(str).where(\n",
        "                df_preprocessed[raw_name].astype(str).str.strip().eq(\"\"),\n",
        "                \"\"  # avoid double-joining if 'raw' already holds full text\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # If that was too clever, just do a simple join with a space fallback\n",
        "    mask_all_empty = df_preprocessed[\"Raw text\"].str.strip().eq(\"\")\n",
        "    df_preprocessed.loc[mask_all_empty, \"Raw text\"] = (\n",
        "        df_preprocessed[raw_name].astype(str).str.strip() + \" \" +\n",
        "        df_preprocessed[text_name].astype(str).str.strip()\n",
        "    ).str.strip()\n",
        "\n",
        "    status(f\"Merged split columns '{raw_name}' + '{text_name}' into 'Raw text'\")\n",
        "else:\n",
        "    if raw_col is None:\n",
        "        status(\"Raw text column not found after parsing\", ok=False)\n",
        "        print(\"Columns present:\", list(df_preprocessed.columns))\n",
        "        raise KeyError(\"'Raw text' column is missing\")\n",
        "    if raw_col != \"Raw text\":\n",
        "        df_preprocessed.rename(columns={raw_col: \"Raw text\"}, inplace=True)\n",
        "        status(f\"Renamed '{raw_col}' to 'Raw text'\")\n",
        "\n",
        "# Clean and verify\n",
        "df_preprocessed[\"Raw text\"] = df_preprocessed[\"Raw text\"].fillna(\"\").astype(str)\n",
        "total = len(df_preprocessed)\n",
        "empty = df_preprocessed[\"Raw text\"].str.strip().eq(\"\").sum()\n",
        "usable = total - empty\n",
        "status(f\"Non-empty 'Raw text' rows: {usable} of {total}\")\n",
        "\n",
        "if usable == 0:\n",
        "    status(\"All 'Raw text' entries are empty after cleaning\", ok=False)\n",
        "    raise ValueError(\"No usable text in 'Raw text'\")\n",
        "\n",
        "# Peek and a quick stat\n",
        "print(\"\\nFirst 5 rows of 'Raw text':\")\n",
        "print(df_preprocessed[[\"Raw text\"]].head(5))\n",
        "\n",
        "avg_len = df_preprocessed[\"Raw text\"].str.len().mean()\n",
        "if pd.isna(avg_len):\n",
        "    avg_len = 0.0\n",
        "status(f\"Average character length across 'Raw text': {avg_len:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 2C — Safer 'Raw text' detection/standardization (NEW)\n",
        "# Run right after Step 2 has created df_preprocessed\n",
        "# ===============================================\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "assert isinstance(df_preprocessed, pd.DataFrame), \"df_preprocessed not defined yet.\"\n",
        "\n",
        "RAW_TEXT_ALIASES = {\n",
        "    \"raw text\",\"raw_text\",\"rawtext\",\"raw-text\",\n",
        "    \"text\",\"writing\",\"essay\",\"response\"\n",
        "}\n",
        "\n",
        "def _norm(h):\n",
        "    return re.sub(r\"\\s+\", \"\", str(h or \"\")).strip().lower()\n",
        "\n",
        "cols = list(df_preprocessed.columns)\n",
        "norm_map = {_norm(c): c for c in cols}\n",
        "\n",
        "raw_col = None\n",
        "\n",
        "# 1) Exact/alias match\n",
        "for alias in RAW_TEXT_ALIASES:\n",
        "    if alias in norm_map:\n",
        "        raw_col = norm_map[alias]\n",
        "        break\n",
        "\n",
        "# 2) Handle split columns literally named 'Raw' and 'Text'\n",
        "if raw_col is None and \"raw\" in norm_map and \"text\" in norm_map:\n",
        "    raw_name  = norm_map[\"raw\"]\n",
        "    text_name = norm_map[\"text\"]\n",
        "    df_preprocessed[\"Raw text\"] = (\n",
        "        df_preprocessed[raw_name].astype(str).fillna(\"\") +\n",
        "        df_preprocessed[text_name].astype(str).fillna(\"\")\n",
        "    ).str.strip()\n",
        "    print(f\"✅ Merged '{raw_name}' + '{text_name}' → 'Raw text'\")\n",
        "else:\n",
        "    # 3) Heuristic: choose the non-ID-like column with the longest average string length\n",
        "    if raw_col is None:\n",
        "        non_id_cols = [c for c in cols if not re.search(r\"\\b(id|identifier|research id)\\b\", str(c), flags=re.I)]\n",
        "        if not non_id_cols:\n",
        "            non_id_cols = cols[-1:]\n",
        "        avg_len = {c: df_preprocessed[c].astype(str).str.len().mean() for c in non_id_cols}\n",
        "        raw_col = max(avg_len, key=avg_len.get)\n",
        "        print(f\"⚠️ Heuristic used: '{raw_col}' chosen as 'Raw text' (longest strings).\")\n",
        "\n",
        "    if raw_col != \"Raw text\":\n",
        "        df_preprocessed.rename(columns={raw_col: \"Raw text\"}, inplace=True)\n",
        "        print(f\"✅ Renamed '{raw_col}' → 'Raw text'\")\n",
        "\n",
        "# Final tidy\n",
        "df_preprocessed[\"Raw text\"] = df_preprocessed[\"Raw text\"].fillna(\"\").astype(str)\n",
        "usable = (~df_preprocessed[\"Raw text\"].str.strip().eq(\"\")).sum()\n",
        "print(f\"✅ Non-empty 'Raw text' rows: {usable}/{len(df_preprocessed)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dbvb6Ygh2eM",
        "outputId": "1aa649dd-8e94-4910-e5b4-e4b54b223ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Non-empty 'Raw text' rows: 21/21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# ID helpers — single source of truth\n",
        "# ============================\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def _norm_header(h: str) -> str:\n",
        "    \"\"\"Lowercase, strip, remove BOM, collapse spaces.\"\"\"\n",
        "    return re.sub(r\"\\s+\", \"\", str(h or \"\").replace(\"\\ufeff\",\"\")).lower()\n",
        "\n",
        "def _normalize_id_series(s: pd.Series) -> pd.Series:\n",
        "    \"\"\"Stringify IDs; fix '123.0'→'123'; keep alphanumerics untouched.\"\"\"\n",
        "    s = s.astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "    def _fix(x):\n",
        "        if any(c.isalpha() for c in x):\n",
        "            return x\n",
        "        try:\n",
        "            if \".\" in x or \"e\" in x.lower():\n",
        "                f = float(x)\n",
        "                if f.is_integer():\n",
        "                    return str(int(f))\n",
        "        except Exception:\n",
        "            pass\n",
        "        return x\n",
        "    return s.map(_fix).fillna(\"\").astype(str)\n",
        "\n",
        "def ensure_canonical_id(df: pd.DataFrame,\n",
        "                        *,\n",
        "                        canon=\"ID\",\n",
        "                        prefer=(\"Research ID\",\"ResearchID\",\"research id\")) -> tuple[pd.DataFrame, str]:\n",
        "    \"\"\"\n",
        "    Return (df_copy_with_ID, source_used)\n",
        "      • Prefer Research ID-like headers if present\n",
        "      • If an 'ID' exists already but is NOT the chosen source, preserve it as 'IdeaID'\n",
        "      • Else synthesize IDs from the index\n",
        "    \"\"\"\n",
        "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        raise ValueError(\"ensure_canonical_id: input df is missing or empty\")\n",
        "\n",
        "    cols = list(df.columns)\n",
        "    nmap = {_norm_header(c): c for c in cols}\n",
        "\n",
        "    # 1) Find preferred source\n",
        "    src = None\n",
        "    for name in prefer:\n",
        "        key = _norm_header(name)\n",
        "        if key in nmap:\n",
        "            src = nmap[key]\n",
        "            break\n",
        "\n",
        "    # 2) If no preferred, consider any existing 'ID'\n",
        "    if src is None and \"id\" in nmap:\n",
        "        src = nmap[\"id\"]\n",
        "\n",
        "    out = df.copy()\n",
        "\n",
        "    # 3) Preserve any existing idea-level 'ID'\n",
        "    had_id = \"ID\" in out.columns\n",
        "    if had_id and (src is not None) and (src != \"ID\"):\n",
        "        if \"IdeaID\" not in out.columns:\n",
        "            out.rename(columns={\"ID\": \"IdeaID\"}, inplace=True)\n",
        "        else:\n",
        "            # leave both; prefer explicit canonical later\n",
        "            pass\n",
        "\n",
        "    # 4) Materialize canonical ID\n",
        "    if src is not None:\n",
        "        out[\"ID\"] = _normalize_id_series(out[src])\n",
        "        used = src\n",
        "        if used != \"ID\":\n",
        "            print(f\"ℹ️  Using '{used}' as canonical 'ID'.\")\n",
        "    else:\n",
        "        out[\"ID\"] = out.index.astype(str)\n",
        "        used = \"synthetic_index\"\n",
        "        print(\"ℹ️  No Research ID/ID found; created synthetic IDs 0..N-1.\")\n",
        "\n",
        "    # 5) Final tidy + peek\n",
        "    out[\"ID\"] = _normalize_id_series(out[\"ID\"])\n",
        "    print(\"🔎 ID check →\", out[\"ID\"].head(5).tolist())\n",
        "\n",
        "    return out, used\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uQ_wz-jpDRhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Step 2A — Canonicalize IDs (prefer Research ID)\n",
        "# ===============================================\n",
        "assert isinstance(df_preprocessed, pd.DataFrame), \"df_preprocessed not defined.\"\n",
        "\n",
        "df_preprocessed, _ID_SOURCE = ensure_canonical_id(\n",
        "    df_preprocessed,\n",
        "    canon=\"ID\",\n",
        "    prefer=(\"Research ID\",\"ResearchID\",\"research id\")\n",
        ")\n",
        "\n",
        "# Put 'ID' first for readability\n",
        "cols = [\"ID\"] + [c for c in df_preprocessed.columns if c != \"ID\"]\n",
        "df_preprocessed = df_preprocessed[cols]\n",
        "\n",
        "# Quick preview of how things landed\n",
        "show_cols = [c for c in (\"Research ID\",\"ResearchID\",\"ID\",\"IdeaID\") if c in df_preprocessed.columns]\n",
        "print(\"Preview of ID-related columns:\")\n",
        "print(df_preprocessed[show_cols].head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJLo2DXinFqE",
        "outputId": "c9625815-0762-4072-f54c-d683e07fe0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️  Using 'Research ID' as canonical 'ID'.\n",
            "🔎 ID check → ['BBCMHJPT', 'BBKBYNDW', 'BBRWTLYV', 'BCDVWQDF', 'BCXSFTWC']\n",
            "Preview of ID-related columns:\n",
            "Research ID       ID  IdeaID\n",
            "   BBCMHJPT BBCMHJPT    1.78\n",
            "   BBKBYNDW BBKBYNDW    0.00\n",
            "   BBRWTLYV BBRWTLYV    3.44\n",
            "   BCDVWQDF BCDVWQDF    3.00\n",
            "   BCXSFTWC BCXSFTWC    1.40\n",
            "   BGRRHYPQ BGRRHYPQ    3.00\n",
            "   BGZZHTXS BGZZHTXS    3.70\n",
            "   BHLQHBRW BHLQHBRW    3.70\n",
            "   BPHVBHZV BPHVBHZV    2.13\n",
            "   BQTNFJFX BQTNFJFX    0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NOTATION: Step 2.1 — Word and Token Stats\n",
        "\n",
        "###Purpose\n",
        "- Add quick length metrics to each row of text so you can sanity check size and plan token budgets.\n",
        "- Two columns are added to df_preprocessed: WordCount and TokenCount.\n",
        "- Estimate how much it would cost to send this dataset to the API, using your per-row TokenCount\n",
        "  and a configurable assumption for output size.\n",
        "\n",
        "###What you may need to change\n",
        "- Nothing for most cases. If you target a specific OpenAI model later, we can switch to its matching tokenizer.\n",
        "-You may need to update the cose of the API call (or could this be updated automatically?).\n",
        "\n",
        "###Inputs\n",
        "- df_preprocessed['Raw text'] produced in Step 2.\n",
        "\n",
        "###Outputs\n",
        "- df_preprocessed with two new numeric columns:\n",
        "    - WordCount  count of whitespace separated words per row\n",
        "    - TokenCount approximate token count per row using tiktoken\n",
        "- Printed checks that show which tokenizer is used, averages, a small distribution summary, and a short preview.\n",
        "- Printed summary: total input tokens, estimated output tokens, and costs for 5 models.\n",
        "- Optional: a small widget to download the DataFrame now as CSV or Excel for manual checks and token and word estimates.\n",
        "\n",
        "###Key ideas\n",
        "- Word counts are simple readability and length signals.\n",
        "- Token counts are model dependent. We try o200k_base first and fall back to cl100k_base, which keeps estimates close to how current OpenAI chat models tokenize text.\n",
        "- API pricing bills both input and output tokens.\n",
        "- We use your TokenCount as “input tokens” and estimate “output tokens” with a single ratio so you can quickly forecast spend.\n",
        "- Keep stats light and fast so they scale to larger datasets.\n",
        "\n",
        "###Verification prints\n",
        "- \"Using tokenizer: ...\" confirms the encoding choice.\n",
        "- \"Average words per Raw text: ...\" and \"Average tokens per Raw text (approx.): ...\" confirm central tendencies.\n",
        "- A min, median, max snapshot for both metrics.\n",
        "- A short preview of the DataFrame with counts.\n",
        "- Shows total rows, total/avg tokens, the output ratio used, and a cost table for:\n",
        "  gpt-4o, gpt-4o-mini, gpt-4.1, gpt-4.1-mini, gpt-3.5-turbo (Standard tier).\n",
        "\n",
        "###Common pitfalls\n",
        "- Running this before Step 2 or without a 'Raw text' column.\n",
        "- Non string entries in 'Raw text'  Step 2 already coerces to strings, so you should be safe.\n",
        "\n",
        "###Actions performed in this code\n",
        "1) Choose a tokenizer and report which one is used.\n",
        "2) Compute WordCount and TokenCount for each row.\n",
        "3) Print summary statistics and show a small preview.\n",
        "4) Offer an optional Download DataFrame button with a format picker\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W518jOrrlwnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Step 2.1: Word and token stats\n",
        "# ===============================================\n",
        "\n",
        "import math\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Optional download widget support\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "    WIDGETS_OK = True\n",
        "except Exception:\n",
        "    WIDGETS_OK = False\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def status(msg, ok=True):\n",
        "    print((\"✅ \" if ok else \"❌ \") + msg)\n",
        "\n",
        "# 1) Choose tokenizer\n",
        "try:\n",
        "    _ENC = tiktoken.get_encoding(\"o200k_base\")\n",
        "    enc_name = \"o200k_base\"\n",
        "except Exception:\n",
        "    _ENC = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    enc_name = \"cl100k_base\"\n",
        "status(f\"Using tokenizer: {enc_name}\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    try:\n",
        "        return len(_ENC.encode(text or \"\"))\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def count_words(text: str) -> int:\n",
        "    if not isinstance(text, str):\n",
        "        return 0\n",
        "    # Simple whitespace split\n",
        "    return len([w for w in text.split() if w.strip()])\n",
        "\n",
        "# 2) Compute counts\n",
        "if \"Raw text\" not in df_preprocessed.columns:\n",
        "    status(\"Missing 'Raw text' column. Run Step 2 first.\", ok=False)\n",
        "    raise KeyError(\"'Raw text' column is missing\")\n",
        "\n",
        "df_preprocessed[\"WordCount\"] = df_preprocessed[\"Raw text\"].apply(count_words)\n",
        "df_preprocessed[\"TokenCount\"] = df_preprocessed[\"Raw text\"].apply(count_tokens)\n",
        "\n",
        "# 3) Summary statistics\n",
        "avg_words = df_preprocessed[\"WordCount\"].mean()\n",
        "avg_tokens = df_preprocessed[\"TokenCount\"].mean()\n",
        "median_words = df_preprocessed[\"WordCount\"].median()\n",
        "median_tokens = df_preprocessed[\"TokenCount\"].median()\n",
        "min_words = df_preprocessed[\"WordCount\"].min()\n",
        "max_words = df_preprocessed[\"WordCount\"].max()\n",
        "min_tokens = df_preprocessed[\"TokenCount\"].min()\n",
        "max_tokens = df_preprocessed[\"TokenCount\"].max()\n",
        "\n",
        "status(f\"Average words per Raw text: {avg_words:.1f}\")\n",
        "status(f\"Average tokens per Raw text (approx.): {avg_tokens:.1f}\")\n",
        "\n",
        "print(\"\\nQuick distribution check:\")\n",
        "print(f\"  Words  → min {min_words}, median {median_words:.0f}, max {max_words}\")\n",
        "print(f\"  Tokens → min {min_tokens}, median {median_tokens:.0f}, max {max_tokens}\")\n",
        "\n",
        "print(\"\\nPreview with counts:\")\n",
        "display(df_preprocessed[[\"Raw text\", \"WordCount\", \"TokenCount\"]].head(5))\n",
        "\n",
        "# 4) Optional: Download DataFrame for checks\n",
        "def _download_df(df, filename=\"df_preprocessed_counts.csv\", file_format=\"csv\"):\n",
        "    local_path = f\"/content/{filename}\"\n",
        "    if file_format.lower() == \"csv\":\n",
        "        df.to_csv(local_path, index=False, encoding=\"utf-8\")\n",
        "    elif file_format.lower() in {\"xlsx\", \"excel\"}:\n",
        "        df.to_excel(local_path, index=False)\n",
        "    else:\n",
        "        raise ValueError(\"Use 'csv' or 'xlsx'\")\n",
        "    files.download(local_path)\n",
        "\n",
        "if WIDGETS_OK:\n",
        "    fmt_dd = widgets.Dropdown(\n",
        "        options=[(\"CSV\", \"csv\"), (\"Excel (.xlsx)\", \"xlsx\")],\n",
        "        value=\"csv\",\n",
        "        description=\"Format:\",\n",
        "        layout=widgets.Layout(width=\"240px\")\n",
        "    )\n",
        "    dl_btn = widgets.Button(\n",
        "        description=\"Download DataFrame now\",\n",
        "        button_style=\"primary\",\n",
        "        tooltip=\"Click to download the DataFrame with WordCount and TokenCount\"\n",
        "    )\n",
        "    out = widgets.Output()\n",
        "\n",
        "    def on_click_download(_):\n",
        "        with out:\n",
        "            out.clear_output()\n",
        "            try:\n",
        "                _download_df(df_preprocessed, filename=\"df_preprocessed_counts.\" + fmt_dd.value, file_format=fmt_dd.value)\n",
        "                print(f\"Started download as df_preprocessed_counts.{fmt_dd.value}\")\n",
        "            except Exception as e:\n",
        "                print(\"Download failed:\", e)\n",
        "\n",
        "    dl_btn.on_click(on_click_download)\n",
        "    display(HTML(\"<b>Do you want to download the DataFrame now for checks?</b>\"))\n",
        "    display(widgets.HBox([fmt_dd, dl_btn]), out)\n",
        "else:\n",
        "    print(\"\\nWidgets not available. To download manually, run:\")\n",
        "    print(\"  df_preprocessed.to_csv('/content/df_preprocessed_counts.csv', index=False, encoding='utf-8')\")\n",
        "    print(\"  from google.colab import files; files.download('/content/df_preprocessed_counts.csv')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412,
          "referenced_widgets": [
            "de3d763ecee449439e9e2f59e8aba021",
            "0cbe64ca836b45cda22d02345dcf0091",
            "91651029021545fd995c893e6d74fb90",
            "e00a959c21c54d8593f8b2ca9b7936fa",
            "084377e1ea52447c9e47212bb32c94a5",
            "ed1b22b478c345038fa4702cd53b9451",
            "a38317f577ee42f9bc15322d524a4f19",
            "573cf0a44f4e44adbc61f011fcd5ede5",
            "c126e1e7c9f6442aad8974ee2411d2e8",
            "f345f48e25ea4d6abfec3c84f2f116f6"
          ]
        },
        "id": "NHKls5vxkN5-",
        "outputId": "1782ea8b-399d-4d15-9170-97d272106432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using tokenizer: o200k_base\n",
            "✅ Average words per Raw text: 284.1\n",
            "✅ Average tokens per Raw text (approx.): 347.1\n",
            "\n",
            "Quick distribution check:\n",
            "  Words  → min 5, median 243, max 706\n",
            "  Tokens → min 6, median 275, max 822\n",
            "\n",
            "Preview with counts:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            Raw text  WordCount  TokenCount\n",
              "0  There once was a girl called lilly she had pet...         52          61\n",
              "1  wrire a narrative story abouta search for some...         43          53\n",
              "2  The Failed Submarine I had always wanted go on...        494         578\n",
              "3  The diamond ring Emmy was just having breakfas...        243         275\n",
              "4  If you are locking for a dimiens go to most di...         57          71"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77d17ffe-a15b-451d-a2b9-5f4bde86c31e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Raw text</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>TokenCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There once was a girl called lilly she had pet...</td>\n",
              "      <td>52</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wrire a narrative story abouta search for some...</td>\n",
              "      <td>43</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Failed Submarine I had always wanted go on...</td>\n",
              "      <td>494</td>\n",
              "      <td>578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The diamond ring Emmy was just having breakfas...</td>\n",
              "      <td>243</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If you are locking for a dimiens go to most di...</td>\n",
              "      <td>57</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77d17ffe-a15b-451d-a2b9-5f4bde86c31e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77d17ffe-a15b-451d-a2b9-5f4bde86c31e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77d17ffe-a15b-451d-a2b9-5f4bde86c31e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-740c3683-b775-49b2-ac0d-f99383e7517d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-740c3683-b775-49b2-ac0d-f99383e7517d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-740c3683-b775-49b2-ac0d-f99383e7517d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"  from google\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Raw text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"wrire a narrative story abouta search for some thing. your story could be about a plaace or a searck for an obj ect. lt could be you can what happens if it isn own idea adout a search for something. information orbs WH\",\n          \"If you are locking for a dimiens go to most diming most dimiens it will tack abort 2 days and will ayiss and mabbing will tack 2 wecks if you are luck and most liy tack for ayissits the bist idere and do not git my stared with the ufvor was to fined dimiens im dun telling.\",\n          \"The Failed Submarine I had always wanted go on a submarine, especially a Sub 2, a type of submarine that has every thing you can think of. Floating chairs, luxurious king sized beds, rooms as large as a house, those were all average features on a Sub 2. But the major problem was the 'bargain' price. It was only about a few thousand dollars a night to go on an underwater and moving 'hotel'. But that became possible after we got an email from the NSW Lotteries giving us a few million dollars after we won. The first thing I did was persuade my mum into going on a Sub 2 trip for a few nights, and she, at last, reluctantly agreed to go on a few nights around Australia. Hopes high, I boarded the luxury submarine, and the first thing my family and I did was go to the dining room. We sat on floating recliners and ate pricey food made by a private chef on a floating table the size of a bus. But the highlight of the trip around Australia was the rooms we had booked for rooms for the journey. The door was unlocked by Face ID, and we were greated to a spectacular dining room with an underwater view. As we plonked down onto the hovering king-sized beds, the boat stopped gliding through the ocean like a knife. Assuming that it was normal, we started jumping on the bed. Suddenly, disaster struck, like lightening to a tree. The glass pane that gave us an underwater view cracked like hammer to a rice cracker. Pools of water rushed into the immense room as the waves pushed against us without mercy. We paddled out the window, and for a vertiginous moment, my family and I felt like drowning as we realised we were about a hundred meters below sea level, but the moment left as soon as it had come. I kicked my legs as brutally as I could, one hand paddling and the other clutched onto Mum. At last, I broke free of the nightmare and I was inhaling lungfulls of fresh, salty air, overwhelmed to be at the surface rather than the bottom. But it wasn't over. We were still hundreds of meters away from a sandy shore. I paddled for hours, my thigh and arms screaming at my head in pain. My family was in the same boat as me as Mum just decided to glide smoothly through the cool water. After a few hours of breathing and kicking and breathing and kicking, a familiar beach came in site. It was Bondi. I was fulled to the brim of joy, and I paddked hard with the strength I suddenly knew I had. I stood like a hero. I wanted to fell the highest spruce and strip it and trim it clean with my bare hands with the strength I knew I had, before collapsing in pools of tears.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WordCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 195,\n        \"min\": 43,\n        \"max\": 494,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          43,\n          57,\n          494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TokenCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 226,\n        \"min\": 53,\n        \"max\": 578,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          53,\n          71,\n          578\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<b>Do you want to download the DataFrame now for checks?</b>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Dropdown(description='Format:', layout=Layout(width='240px'), options=(('CSV', 'csv'), ('Excel …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de3d763ecee449439e9e2f59e8aba021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c126e1e7c9f6442aad8974ee2411d2e8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Normalizer upgrade (place once, e.g., after Step 2) =====\n",
        "import re\n",
        "\n",
        "def normalize_mojibake(s: str) -> str:\n",
        "    \"\"\"Lightweight repairs for common mojibake + whitespace cleanup.\"\"\"\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = str(s)\n",
        "\n",
        "    # Classic UTF-8-as-Win1252 sequences\n",
        "    fixes = {\n",
        "        \"â€”\": \"—\",   # em dash\n",
        "        \"â€“\": \"–\",   # en dash\n",
        "        \"â€˜\": \"‘\", \"â€™\": \"’\",  # single quotes\n",
        "        \"â€œ\": \"“\", \"â€\\x9d\": \"”\", \"â€\\x9c\": \"“\",  # double quotes variants\n",
        "        \"â€¦\": \"…\",   # ellipsis\n",
        "        \"â€¢\": \"•\",   # bullet\n",
        "        \"â€\": \"”\",    # stray\n",
        "    }\n",
        "    for bad, good in fixes.items():\n",
        "        s = s.replace(bad, good)\n",
        "\n",
        "    # Collapse weird spaces and trim\n",
        "    s = re.sub(r\"[ \\t\\u00A0\\u2007\\u202F]+\", \" \", s).strip()\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "oT1ucd0JCpxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lARfpftGu1Lw"
      },
      "source": [
        "# Step 3: Install and Import Required Libraries\n",
        "\n",
        "###Purpose\n",
        "- Ensure the exact Python libraries and language models you need are installed and working.\n",
        "- Verify imports and show clear version numbers so you can troubleshoot quickly.\n",
        "\n",
        "###What you may need to change\n",
        "- Library versions, if you want to pin different ones for compatibility.\n",
        "- You can remove the openai uninstall if you are sure the environment is clean.\n",
        "\n",
        "###Inputs\n",
        "- Internet access in the Colab runtime to download packages and the spaCy model.\n",
        "\n",
        "###Outputs\n",
        "- Installed packages: openai, tqdm, nltk, tiktoken, spacy, pandas.\n",
        "- Downloaded spaCy model: en_core_web_sm.\n",
        "- Verified imports with printed version numbers.\n",
        "- NLTK tokenizers available: punkt and punkt_tab.\n",
        "\n",
        "###Key ideas\n",
        "- Pin versions when you want reproducibility. The defaults below are stable and pair well with Colab.\n",
        "- spaCy needs a separate model download. We fetch en_core_web_sm and then test a tiny parse.\n",
        "- NLTK recently split tokenizers, so we check both punkt and punkt_tab.\n",
        "\n",
        "###Verification prints\n",
        "- Package versions for openai, pandas, spacy, nltk, tiktoken, tqdm.\n",
        "- Confirmation that spaCy model loads and can process a sentence.\n",
        "- Confirmation that NLTK tokenizers are present.\n",
        "- A tiny tiktoken encode test to confirm the tokenizer is usable.\n",
        "\n",
        "###Common pitfalls\n",
        "- Conflicting preinstalled openai versions. We uninstall first to avoid API mismatch.\n",
        "- Missing spaCy model. Installing the library is not enough, you must download a model.\n",
        "- NLTK data not present. We fetch tokenizers to avoid runtime errors later.\n",
        "\n",
        "###Actions performed in this code\n",
        "1) Uninstall any preinstalled openai to avoid conflicts.\n",
        "2) Install required libraries with pinned versions.\n",
        "3) Download the spaCy English model en_core_web_sm.\n",
        "4) Import libraries and print versions.\n",
        "5) Verify spaCy model load.\n",
        "6) Verify NLTK tokenizers punkt and punkt_tab.\n",
        "7) Verify tiktoken by encoding a short string.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "#3.1 — Install / Upgrade (run once)\n",
        "# -----------------------\n",
        "# Uninstall preinstalled openai versions to avoid conflicts, then install v1 + dependencies\n",
        "!pip -q uninstall -y openai\n",
        "!pip -q install --upgrade \"openai==1.*\" tqdm nltk tiktoken spacy pandas==2.2.2 ipywidgets openpyxl jsonschema\n",
        "\n",
        "# Download spaCy small model\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "\n",
        "\n",
        "\n",
        "print(\"⬇️ Install step finished. IMPORTANT: Restart the runtime (Runtime > Restart runtime) and then run the verification cell.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7ATUrujfg4L",
        "outputId": "d8998272-ab6a-455b-9905-fe7385829cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/12.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/12.8 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m167.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m167.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "⬇️ Install step finished. IMPORTANT: Restart the runtime (Runtime > Restart runtime) and then run the verification cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yozAyKwAETk-",
        "outputId": "8e5fde6d-8b9f-4a34-a94d-d589a82acba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versions:\n",
            "  openai: 1.109.1\n",
            "  pandas: 2.2.2\n",
            "  spacy: 3.8.7\n",
            "  nltk: 3.9.2\n",
            "  tiktoken: 0.12.0\n",
            "  tqdm: 4.67.1\n",
            "  ipywidgets: 7.7.1\n",
            "  openpyxl: 3.1.5\n",
            "  jsonschema: 4.25.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-862085380.py:11: DeprecationWarning: Accessing jsonschema.__version__ is deprecated and will be removed in a future release. Use importlib.metadata directly to query for jsonschema's version.\n",
            "  return getattr(m, \"__version__\", \"unknown\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ spaCy loaded and tokenized sample: ['A', 'tiny', 'sanity', 'check', '.']\n",
            "✅ NLTK 'punkt' tokenizer is present.\n",
            "✅ tiktoken ready with o200k_base. Sample tokens: 5\n"
          ]
        }
      ],
      "source": [
        "# -----------------------\n",
        "#3.2 — Imports, version checks, and tokenizer / model verification\n",
        "# -----------------------\n",
        "import importlib, sys, os, logging\n",
        "from getpass import getpass\n",
        "\n",
        "# Helper to report versions safely\n",
        "def v(name):\n",
        "    try:\n",
        "        m = importlib.import_module(name)\n",
        "        return getattr(m, \"__version__\", \"unknown\")\n",
        "    except Exception as e:\n",
        "        return f\"import failed: {e}\"\n",
        "\n",
        "modules = [\"openai\",\"pandas\",\"spacy\",\"nltk\",\"tiktoken\",\"tqdm\",\"ipywidgets\",\"openpyxl\",\"jsonschema\"]\n",
        "print(\"Versions:\")\n",
        "for name in modules:\n",
        "    print(f\"  {name}: {v(name)}\")\n",
        "\n",
        "# spaCy load check\n",
        "import spacy\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(\"A tiny sanity check.\")\n",
        "    print(\"✅ spaCy loaded and tokenized sample:\", [t.text for t in doc])\n",
        "except Exception as e:\n",
        "    print(\"❌ spaCy failed to load:\", e)\n",
        "    raise\n",
        "\n",
        "# NLTK tokenizers\n",
        "import nltk\n",
        "NLTK_DIR = \"/content/nltk_data\"\n",
        "os.makedirs(NLTK_DIR, exist_ok=True)\n",
        "if NLTK_DIR not in nltk.data.path:\n",
        "    nltk.data.path.insert(0, NLTK_DIR)\n",
        "\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt\")\n",
        "    print(\"✅ NLTK 'punkt' tokenizer is present.\")\n",
        "except LookupError:\n",
        "    print(\"⬇️ Downloading NLTK 'punkt' tokenizer...\")\n",
        "    nltk.download(\"punkt\", download_dir=NLTK_DIR, quiet=False)\n",
        "    try:\n",
        "        nltk.data.find(\"tokenizers/punkt\")\n",
        "        print(\"✅ 'punkt' downloaded.\")\n",
        "    except LookupError:\n",
        "        print(\"❌ Failed to download 'punkt'.\")\n",
        "\n",
        "# tiktoken check\n",
        "import tiktoken\n",
        "try:\n",
        "    enc = None\n",
        "    try:\n",
        "        enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "        enc_name = \"o200k_base\"\n",
        "    except Exception:\n",
        "        enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "        enc_name = \"cl100k_base\"\n",
        "    n_tokens = len(enc.encode(\"Tokenization sanity check.\"))\n",
        "    print(f\"✅ tiktoken ready with {enc_name}. Sample tokens: {n_tokens}\")\n",
        "except Exception as e:\n",
        "    print(\"❌ tiktoken failed:\", e)\n",
        "    raise\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4.1: Optional Preempt — install common extras up front\n",
        "###Purpose\n",
        "- Preemptively install/verify common libraries and language data you’re likely to need later\n",
        "  so downstream steps don’t break mid-run.\n",
        "\n",
        "#What you may need to change\n",
        "- Toggle WANT_SPACY_MD to True if you want the larger 'en_core_web_md' spaCy model.\n",
        "- Adjust VERS pins if you prefer different versions.\n",
        "\n",
        "#Installs/Verifies\n",
        "- Libraries: ipywidgets, openpyxl (Excel export), matplotlib (plots), chardet (encoding detect),\n",
        "             pyarrow (faster IO). xlsxwriter optional as an alternate Excel engine.\n",
        "- NLTK data: punkt, punkt_tab (if available), stopwords, wordnet, omw-1.4.\n",
        "- spaCy model: ensures 'en_core_web_sm' is present; optionally downloads 'en_core_web_md'.\n",
        "\n",
        "#Outputs\n",
        "- Clear prints of what was installed or already present, plus quick sanity checks."
      ],
      "metadata": {
        "id": "SKn7iR-k_MhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ----------------- toggles -----------------\n",
        "WANT_SPACY_MD = False   # True to also download/load en_core_web_md\n",
        "# ------------------------------------------\n",
        "\n",
        "import sys, os, shutil, subprocess, importlib\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def _pip_install(spec):\n",
        "    print(f\"⬇️  Installing {spec} ...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", spec])\n",
        "\n",
        "def ensure_pkg(mod_name, spec=None):\n",
        "    try:\n",
        "        m = importlib.import_module(mod_name)\n",
        "        print(f\"✅ {mod_name} already available\")\n",
        "    except Exception:\n",
        "        _pip_install(spec or mod_name)\n",
        "        m = importlib.import_module(mod_name)\n",
        "        print(f\"✅ {mod_name} installed\")\n",
        "    return m\n",
        "\n",
        "def print_version(mod_name):\n",
        "    try:\n",
        "        m = importlib.import_module(mod_name)\n",
        "        v = getattr(m, \"__version__\", \"unknown\")\n",
        "        print(f\"   • {mod_name} {v}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   • {mod_name} version check failed: {e}\")\n",
        "\n",
        "# ---------- core convenience libraries ----------\n",
        "ipywidgets = ensure_pkg(\"ipywidgets\", \"ipywidgets==8.1.1\")\n",
        "openpyxl   = ensure_pkg(\"openpyxl\",   \"openpyxl>=3.1.2\")\n",
        "matplotlib = ensure_pkg(\"matplotlib\", \"matplotlib>=3.8.0\")\n",
        "chardet    = ensure_pkg(\"chardet\",    \"chardet>=5.2.0\")\n",
        "pyarrow    = ensure_pkg(\"pyarrow\",    \"pyarrow>=16.1.0\")\n",
        "# Optional alternative Excel writer:\n",
        "# xlsxwriter = ensure_pkg(\"xlsxwriter\", \"XlsxWriter>=3.2.0\")\n",
        "\n",
        "print(\"\\nVersions:\")\n",
        "for name in [\"ipywidgets\", \"openpyxl\", \"matplotlib\", \"chardet\", \"pyarrow\"]:\n",
        "    print_version(name)\n",
        "\n",
        "# ---------- NLTK: one directory, robust downloads ----------\n",
        "nltk = ensure_pkg(\"nltk\", \"nltk>=3.8.1\")\n",
        "\n",
        "NLTK_DIR = \"/content/nltk_data\"\n",
        "os.makedirs(NLTK_DIR, exist_ok=True)\n",
        "os.environ[\"NLTK_DATA\"] = NLTK_DIR\n",
        "# put our folder at the front of the search path\n",
        "if NLTK_DIR in nltk.data.path:\n",
        "    nltk.data.path.remove(NLTK_DIR)\n",
        "nltk.data.path.insert(0, NLTK_DIR)\n",
        "\n",
        "print(\"\\nNLTK search paths (in order):\")\n",
        "for p in nltk.data.path:\n",
        "    print(\"  -\", p)\n",
        "\n",
        "def ensure_nltk_resource(resource, kind=\"corpora\", retries=2, clean_if_stuck=True):\n",
        "    \"\"\"\n",
        "    Ensure NLTK resource (e.g. 'wordnet') exists under NLTK_DIR/kind.\n",
        "    Retries and optionally removes a partial folder if verification fails.\n",
        "    \"\"\"\n",
        "    resource_path = f\"{kind}/{resource}\"\n",
        "    target_folder = os.path.join(NLTK_DIR, kind, resource)\n",
        "\n",
        "    def _verified():\n",
        "        try:\n",
        "            nltk.data.find(resource_path)\n",
        "            return True\n",
        "        except LookupError:\n",
        "            return False\n",
        "\n",
        "    if _verified():\n",
        "        print(f\"✅ NLTK {kind} '{resource}' available\")\n",
        "        return\n",
        "\n",
        "    if clean_if_stuck and os.path.isdir(target_folder):\n",
        "        print(f\"🧹 Removing partial folder: {target_folder}\")\n",
        "        shutil.rmtree(target_folder, ignore_errors=True)\n",
        "\n",
        "    for attempt in range(1, retries + 1):\n",
        "        print(f\"⬇️  Downloading NLTK {kind} '{resource}' (attempt {attempt}/{retries}) ...\")\n",
        "        ok = nltk.download(resource, download_dir=NLTK_DIR, quiet=False)\n",
        "        exists_flag = os.path.isdir(target_folder)\n",
        "        verified = _verified()\n",
        "        print(f\"   ↳ folder exists: {exists_flag}; verified: {verified}; downloader_returned: {ok}\")\n",
        "        if exists_flag and verified:\n",
        "            print(f\"✅ NLTK {kind} '{resource}' ready at {target_folder}\")\n",
        "            return\n",
        "\n",
        "    # Last resort: show directory state and fail\n",
        "    parent = os.path.join(NLTK_DIR, kind)\n",
        "    print(f\"❌ Could not verify NLTK {kind} '{resource}' after {retries} attempts.\")\n",
        "    print(\"   Contents of\", parent, \":\", os.listdir(parent) if os.path.isdir(parent) else \"(missing)\")\n",
        "    raise LookupError(f\"Failed to ensure NLTK {resource_path}\")\n",
        "\n",
        "# Tokenizers\n",
        "ensure_nltk_resource(\"punkt\", kind=\"tokenizers\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNSlQwSI_JrW",
        "outputId": "ae9128f6-aa8c-49b6-961d-4b945997a2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ipywidgets already available\n",
            "✅ openpyxl already available\n",
            "✅ matplotlib already available\n",
            "✅ chardet already available\n",
            "✅ pyarrow already available\n",
            "\n",
            "Versions:\n",
            "   • ipywidgets 7.7.1\n",
            "   • openpyxl 3.1.5\n",
            "   • matplotlib 3.10.0\n",
            "   • chardet 5.2.0\n",
            "   • pyarrow 18.1.0\n",
            "✅ nltk already available\n",
            "\n",
            "NLTK search paths (in order):\n",
            "  - /content/nltk_data\n",
            "  - /root/nltk_data\n",
            "  - /usr/nltk_data\n",
            "  - /usr/share/nltk_data\n",
            "  - /usr/lib/nltk_data\n",
            "  - /usr/share/nltk_data\n",
            "  - /usr/local/share/nltk_data\n",
            "  - /usr/lib/nltk_data\n",
            "  - /usr/local/lib/nltk_data\n",
            "✅ NLTK tokenizers 'punkt' available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoZ8yJw4vZMZ"
      },
      "source": [
        "# Step 4: Import Required Libraries\n",
        "###Purpose\n",
        "- Import the libraries used for data processing, NLP, tokenisation, logging, and progress bars.\n",
        "- Load the spaCy English model prepared in Step 3.\n",
        "- Run quick sanity checks so you know everything is working before you proceed.\n",
        "\n",
        "###What you may need to change\n",
        "- Nothing in most cases. If you installed a different spaCy model name, update MODEL_NAME below.\n",
        "\n",
        "###Inputs\n",
        "- Installed packages from Step 3. SpaCy model en_core_web_sm should already be present.\n",
        "\n",
        "###Outputs\n",
        "- Imported modules in memory.\n",
        "- tqdm progress bars enabled for pandas operations.\n",
        "- A loaded spaCy pipeline in the variable `nlp`.\n",
        "- Short verification prints from spaCy, NLTK, and tiktoken.\n",
        "\n",
        "###Key ideas\n",
        "- Keep imports in one place so the rest of the notebook can assume they exist.\n",
        "- Fail early with clear messages if a critical import or model is missing.\n",
        "\n",
        "###Verification prints\n",
        "- Confirms tqdm was enabled.\n",
        "- Confirms spaCy loaded and tokenised a tiny sentence.\n",
        "- Confirms NLTK tokeniser works.\n",
        "- Confirms tiktoken can encode a short string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB_87Io4Ehog",
        "outputId": "4f7a83c2-01dd-477d-e14e-2e363742b78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 Step 4 imports and model load verified.\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# Step 4: Import Required Libraries\n",
        "# ===============================================\n",
        "\n",
        "# ================================\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import string\n",
        "import random\n",
        "import threading\n",
        "import logging\n",
        "import difflib\n",
        "from functools import lru_cache\n",
        "\n",
        "# Set up logging for helpful debug output\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
        "\n",
        "# Ensure deterministic-ish behaviour for debugging\n",
        "random.seed(1)\n",
        "\n",
        "# Pandas + tqdm\n",
        "import pandas as pd\n",
        "try:\n",
        "    # prefer notebook tqdm if available\n",
        "    from tqdm.notebook import tqdm\n",
        "except Exception:\n",
        "    from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "logging.info(\"✅ tqdm progress bars enabled for pandas\")\n",
        "\n",
        "# NLTK setup\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "NLTK_DIR = \"/content/nltk_data\" if os.path.exists(\"/content\") else os.path.join(os.getcwd(), \"nltk_data\")\n",
        "os.makedirs(NLTK_DIR, exist_ok=True)\n",
        "if NLTK_DIR not in nltk.data.path:\n",
        "    nltk.data.path.insert(0, NLTK_DIR)\n",
        "\n",
        "# Download 'punkt' if missing, but keep output quiet unless it fails\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt\")\n",
        "    logging.info(\"✅ NLTK 'punkt' tokenizer present\")\n",
        "except LookupError:\n",
        "    logging.info(\"⬇️ Downloading NLTK 'punkt' tokenizer...\")\n",
        "    nltk.download(\"punkt\", download_dir=NLTK_DIR, quiet=True)\n",
        "    try:\n",
        "        nltk.data.find(\"tokenizers/punkt\")\n",
        "        logging.info(\"✅ NLTK 'punkt' downloaded\")\n",
        "    except LookupError:\n",
        "        raise RuntimeError(\"NLTK 'punkt' tokenizer download failed. Check network or permissions.\")\n",
        "\n",
        "# spaCy + model load (single load only)\n",
        "import spacy\n",
        "MODEL_NAME = \"en_core_web_sm\"\n",
        "try:\n",
        "    nlp = spacy.load(MODEL_NAME)\n",
        "    _doc = nlp(\"Quick spaCy check.\")\n",
        "    logging.info(\"✅ spaCy model loaded (%s). Tokens: %s\", MODEL_NAME, [t.text for t in _doc])\n",
        "except Exception as e:\n",
        "    logging.error(\"❌ Could not load spaCy model '%s': %s\", MODEL_NAME, e)\n",
        "    logging.info(\"Tip: re-run your install cell to fetch the model, then restart the runtime.\")\n",
        "    raise\n",
        "\n",
        "# tiktoken robust selection\n",
        "import tiktoken\n",
        "def get_token_encoder(preferred=(\"o200k_base\", \"cl100k_base\")):\n",
        "    names = []\n",
        "    try:\n",
        "        names = tiktoken.list_encoding_names()\n",
        "    except Exception:\n",
        "        # older tiktoken versions may not expose list_encoding_names\n",
        "        pass\n",
        "    for enc in preferred:\n",
        "        try:\n",
        "            if names and enc not in names:\n",
        "                continue\n",
        "            return tiktoken.get_encoding(enc)\n",
        "        except Exception:\n",
        "            continue\n",
        "    # final fallback to a known encoding name if available\n",
        "    try:\n",
        "        return tiktoken.get_encoding(\"cl100k_base\")\n",
        "    except Exception as e:\n",
        "        logging.error(\"❌ tiktoken encoders unavailable: %s\", e)\n",
        "        raise\n",
        "\n",
        "ENC = get_token_encoder()\n",
        "_enc_name = getattr(ENC, \"__name__\", \"encoding\")\n",
        "_sample_len = len(ENC.encode(\"Tiny tiktoken check.\"))\n",
        "logging.info(\"✅ tiktoken ready (%s). Sample length: %d\", _enc_name, _sample_len)\n",
        "\n",
        "print(\"🎉 Step 4 imports and model load verified.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YYHYg-lvkQ_"
      },
      "source": [
        "# Step 5 — Configure Logging\n",
        "\n",
        "###Purpose\n",
        "- Capture info, warnings, and errors to both the Colab console and a log file for later debugging.\n",
        "- Adjust logging settings from a small UI: filenames, console/file levels, rotation size/backups.\n",
        "- Make log levels easy to change for noisy vs quiet runs.\n",
        "\n",
        "- Apply the config, run a tiny self-test, optionally preview the log tail, and download the log.\n",
        "\n",
        "\n",
        "###What you can change via UI\n",
        "- LOG_FILE: filename of the rotating log\n",
        "- CONSOLE_LEVEL: how noisy the notebook output is\n",
        "- FILE_LEVEL: how detailed the on-disk log is\n",
        "- ROTATE_MAX_MB: size per log file before rotation\n",
        "- ROTATE_BACKUPS: how many rotated files to keep\n",
        "\n",
        "###Outputs\n",
        "- Reconfigured root logger with a StreamHandler (console) and RotatingFileHandler (file)\n",
        "- Self-test entries written to the log\n",
        "- Optional log tail preview\n",
        "\n",
        "###Key ideas\n",
        "- Set the root logger level high enough to allow through what handlers need.\n",
        "- Handlers have their own levels. Console can be quieter than file.\n",
        "- Rotating logs prevent a single giant file.\n",
        "\n",
        "###Verification prints\n",
        "- A quick self test logs INFO, WARNING, ERROR, and an example exception.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "642ac1f6f9ac4e55be4d98bc4a59c363",
            "2dac6b65232e41e2864f7109878bd7c7",
            "6962d7dbc9824c52b6fa73f62c7afd18",
            "6cdf86d04f334ebfa0b2a25cf077b108",
            "8d692e65004642c8a71732b4ac09fdb5",
            "9c61613cb7494ff29253eb302cb68883",
            "d0d5c54cc51a421e9740de1e952fe97c",
            "ebd54a5e2551483c84415e62ab4cb190",
            "6003d7e673d143f186eb20118b99c449",
            "7729ca1562024e248e1fda751ba7419a",
            "05cc2de09f45485a8e866fddc4b4cd86",
            "c005febb173b4713ba82370fdf852b6b",
            "43a3bd9d92c04658ba5ae4865b1c7fe0",
            "c532338581d2429e90fc6fe55eb8e0db",
            "ac36d91201034ba59067477bd436909c",
            "fc366d499fe44373a5fbffc4fa5d4194",
            "964859d1269148f18025b853593d9ba0",
            "3c4029a0339243aa80b8c877a2f8d4ee",
            "7eb5afcd7f6d4e7bb03533bad2a6b7ad",
            "6335828f32744e61a09b7509658b81e0",
            "233086638fc44d07be166499e1575aa0",
            "c174822677b84b6099f4bbcff5673bc6",
            "203a9d7301d941c99ad37428f77f9435",
            "825f68bbcd984df0b53f4d1b32179f49",
            "6fb24ec72a424f91a9e6646d6ccde3d5",
            "3a5095671e684c2f9372d81d96f0f0b3",
            "966cc2aea794474fac115f19d4bb924a",
            "4b88c4c8354c475c99feb02bb7cee1f6",
            "06e9045b478542d39f5a88ac466c500f",
            "2f0f5543d01c41e195729df06c58095c",
            "1fde0096dc0b474ea6392288835c90c2",
            "ef45aa6a8cb847cea8db908f775edf8d",
            "dbcbeb8b6390453fa24d1624a30ac3f4",
            "8c038de713b9412d90abeb136a2e57ad"
          ]
        },
        "id": "l0m7W001J_fm",
        "outputId": "9ccb2246-1149-42ae-bd6e-ac4b760b3b9d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4>Logging Control Panel</h4>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='text_correction.log', description='LOG_FILE:', layout=Layout(width='420px')), HBox(…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "642ac1f6f9ac4e55be4d98bc4a59c363"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os, io, logging, traceback\n",
        "from logging.handlers import RotatingFileHandler\n",
        "from IPython.display import display, HTML\n",
        "try:\n",
        "    import ipywidgets as widgets\n",
        "    WIDGETS_OK = True\n",
        "except Exception:\n",
        "    WIDGETS_OK = False\n",
        "\n",
        "# ---- helper: make or update logging based on UI values ----\n",
        "def configure_logging(log_file: str,\n",
        "                      console_level: int,\n",
        "                      file_level: int,\n",
        "                      rotate_max_mb: int,\n",
        "                      rotate_backups: int) -> logging.Logger:\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.DEBUG)  # always let handlers filter\n",
        "\n",
        "    # Remove old handlers (avoids duplicates on re-run)\n",
        "    for h in list(logger.handlers):\n",
        "        logger.removeHandler(h)\n",
        "\n",
        "    fmt = logging.Formatter(\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\")\n",
        "\n",
        "    # Console\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(console_level)\n",
        "    ch.setFormatter(fmt)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    # Rotating file\n",
        "    fh = RotatingFileHandler(\n",
        "        log_file,\n",
        "        maxBytes=rotate_max_mb * 1024 * 1024,\n",
        "        backupCount=rotate_backups,\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    fh.setLevel(file_level)\n",
        "    fh.setFormatter(fmt)\n",
        "    logger.addHandler(fh)\n",
        "\n",
        "    # Chattery libs can be quieted if you like\n",
        "    logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
        "    logging.getLogger(\"tqdm\").setLevel(logging.WARNING)\n",
        "\n",
        "    # Self-test\n",
        "    logger.info(\"Logging control panel: INFO test\")\n",
        "    logger.warning(\"Logging control panel: WARNING test\")\n",
        "    try:\n",
        "        1/0\n",
        "    except ZeroDivisionError:\n",
        "        logger.error(\"Logging control panel: ERROR test with traceback\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "    return logger\n",
        "\n",
        "# ---- level maps for dropdowns ----\n",
        "LEVELS = {\n",
        "    \"DEBUG (most verbose)\": logging.DEBUG,\n",
        "    \"INFO (standard)\": logging.INFO,\n",
        "    \"WARNING (only important)\": logging.WARNING,\n",
        "    \"ERROR (failures only)\": logging.ERROR,\n",
        "    \"CRITICAL\": logging.CRITICAL\n",
        "}\n",
        "\n",
        "# ---- defaults (you can change here if you want different initial values) ----\n",
        "DEFAULT_LOG_FILE = \"text_correction.log\"\n",
        "DEFAULT_CONSOLE = \"INFO (standard)\"\n",
        "DEFAULT_FILE = \"DEBUG (most verbose)\"\n",
        "DEFAULT_ROTATE_MB = 5\n",
        "DEFAULT_BACKUPS = 3\n",
        "\n",
        "if not WIDGETS_OK:\n",
        "    print(\"ipywidgets not available. Install it first or run the preempt cell. \"\n",
        "          \"Meanwhile, you can configure logging programmatically via Step 5.\")\n",
        "else:\n",
        "    # ---- UI controls ----\n",
        "    log_file_text = widgets.Text(\n",
        "        value=DEFAULT_LOG_FILE,\n",
        "        description=\"LOG_FILE:\",\n",
        "        layout=widgets.Layout(width=\"420px\")\n",
        "    )\n",
        "    console_level_dd = widgets.Dropdown(\n",
        "        options=list(LEVELS.keys()),\n",
        "        value=DEFAULT_CONSOLE,\n",
        "        description=\"Console:\",\n",
        "        layout=widgets.Layout(width=\"420px\")\n",
        "    )\n",
        "    file_level_dd = widgets.Dropdown(\n",
        "        options=list(LEVELS.keys()),\n",
        "        value=DEFAULT_FILE,\n",
        "        description=\"File:\",\n",
        "        layout=widgets.Layout(width=\"420px\")\n",
        "    )\n",
        "    rotate_mb_slider = widgets.IntSlider(\n",
        "        value=DEFAULT_ROTATE_MB, min=1, max=50, step=1,\n",
        "        description=\"Rotate MB:\",\n",
        "        readout=True, continuous_update=False\n",
        "    )\n",
        "    backups_slider = widgets.IntSlider(\n",
        "        value=DEFAULT_BACKUPS, min=0, max=20, step=1,\n",
        "        description=\"Backups:\",\n",
        "        readout=True, continuous_update=False\n",
        "    )\n",
        "\n",
        "    apply_btn = widgets.Button(\n",
        "        description=\"Apply logging settings\",\n",
        "        button_style=\"primary\",\n",
        "        tooltip=\"Configure handlers and run a quick self-test\"\n",
        "    )\n",
        "    show_tail_btn = widgets.Button(\n",
        "        description=\"Show log tail\",\n",
        "        tooltip=\"Display the last lines of the current log file\"\n",
        "    )\n",
        "    download_btn = widgets.Button(\n",
        "        description=\"Download log\",\n",
        "        tooltip=\"Download the current log file\"\n",
        "    )\n",
        "    out = widgets.Output()\n",
        "\n",
        "    # ---- callbacks ----\n",
        "    def on_apply_clicked(_):\n",
        "        with out:\n",
        "            out.clear_output()\n",
        "            log_file = log_file_text.value.strip() or DEFAULT_LOG_FILE\n",
        "            console_level = LEVELS[console_level_dd.value]\n",
        "            file_level = LEVELS[file_level_dd.value]\n",
        "            rotate_mb = int(rotate_mb_slider.value)\n",
        "            backups = int(backups_slider.value)\n",
        "\n",
        "            logger = configure_logging(\n",
        "                log_file=log_file,\n",
        "                console_level=console_level,\n",
        "                file_level=file_level,\n",
        "                rotate_max_mb=rotate_mb,\n",
        "                rotate_backups=backups\n",
        "            )\n",
        "            print(\"✅ Applied logging settings\")\n",
        "            print(f\"   LOG_FILE: {log_file}\")\n",
        "            print(f\"   CONSOLE_LEVEL: {console_level_dd.value}\")\n",
        "            print(f\"   FILE_LEVEL: {file_level_dd.value}\")\n",
        "            print(f\"   ROTATE_MAX_MB: {rotate_mb}\")\n",
        "            print(f\"   ROTATE_BACKUPS: {backups}\")\n",
        "            print(\"\\nWrote self-test lines. Use 'Show log tail' to preview.\")\n",
        "\n",
        "    def on_show_tail_clicked(_):\n",
        "        with out:\n",
        "            log_file = log_file_text.value.strip() or DEFAULT_LOG_FILE\n",
        "            out.clear_output()\n",
        "            if not os.path.exists(log_file):\n",
        "                print(f\"❌ Log file not found yet: {log_file}\")\n",
        "                print(\"   Click 'Apply logging settings' first.\")\n",
        "                return\n",
        "            try:\n",
        "                # read last ~100 lines\n",
        "                with open(log_file, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "                    lines = f.readlines()[-100:]\n",
        "                print(f\"--- tail of {log_file} (last {len(lines)} lines) ---\")\n",
        "                for line in lines:\n",
        "                    print(line.rstrip())\n",
        "            except Exception as e:\n",
        "                print(\"❌ Failed to read log:\", e)\n",
        "\n",
        "    def on_download_clicked(_):\n",
        "        from google.colab import files\n",
        "        with out:\n",
        "            out.clear_output()\n",
        "            log_file = log_file_text.value.strip() or DEFAULT_LOG_FILE\n",
        "            if not os.path.exists(log_file):\n",
        "                print(f\"❌ Log file not found: {log_file}\")\n",
        "                print(\"   Click 'Apply logging settings' first.\")\n",
        "                return\n",
        "            try:\n",
        "                files.download(log_file)\n",
        "                print(f\"Started download: {log_file}\")\n",
        "            except Exception as e:\n",
        "                print(\"❌ Download failed:\", e)\n",
        "\n",
        "    apply_btn.on_click(on_apply_clicked)\n",
        "    show_tail_btn.on_click(on_show_tail_clicked)\n",
        "    download_btn.on_click(on_download_clicked)\n",
        "\n",
        "    # ---- layout ----\n",
        "    display(HTML(\"<h4>Logging Control Panel</h4>\"))\n",
        "    display(\n",
        "        widgets.VBox([\n",
        "            log_file_text,\n",
        "            widgets.HBox([console_level_dd, file_level_dd]),\n",
        "            widgets.HBox([rotate_mb_slider, backups_slider]),\n",
        "            widgets.HBox([apply_btn, show_tail_btn, download_btn]),\n",
        "            out\n",
        "        ])\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg-HSr-nvz8a"
      },
      "source": [
        "# Step 6: Securely Prompt for OpenAI API Key and test OpenAI API key\n",
        "\n",
        "###Purpose\n",
        "- Obtain the OpenAI API key securely (without exposing it in code cells).\n",
        "- Verify that the key works by attempting a harmless API call (listing models).\n",
        "\n",
        "###What you may need to change\n",
        "- Nothing. Just run this cell; it will prompt you for the key if it’s not already in memory.\n",
        "\n",
        "###Inputs\n",
        "- User-entered API key (via getpass prompt).\n",
        "\n",
        "###Outputs\n",
        "- Environment variable OPENAI_API_KEY set for this session.\n",
        "- Verification message confirming that the key works, or an error if it doesn’t.\n",
        "\n",
        "###Key ideas\n",
        "- Never hard-code your API key into notebooks.\n",
        "- The key is stored only in the temporary runtime environment variable, not in the notebook file.\n",
        "- Verification uses a lightweight call (model listing).\n",
        "\n",
        "###Verification prints\n",
        "- “✅ OpenAI API key is valid.” if the call succeeds.\n",
        "- A clear “❌ Invalid or failed verification” message if not."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "try:\n",
        "    import openai\n",
        "    print(\"openai version:\", getattr(openai, \"__version__\", \"unknown\"))\n",
        "except Exception as e:\n",
        "    print(\"openai import failed:\", e)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwMpyfVlhAl3",
        "outputId": "762c4035-583d-48c1-fe8e-8ab21d6e2543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openai version: 1.109.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9TSbkS06NoP",
        "outputId": "42463102-2f6b-4b76-dabe-8ac4c485c87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key (input hidden). Press Enter to skip real calls.\n",
            "API key: ··········\n",
            "✅ OpenAI client ready.\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# Step 6 — Secure OpenAI key + global toggle (REPLACE)\n",
        "# ===============================================\n",
        "USE_OPENAI = True  # ← set to False for dry-run/mock mode (no paid calls)\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "def _ensure_openai_key():\n",
        "    \"\"\"Prompt once (hidden) and store only in env for this session.\"\"\"\n",
        "    key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if key:\n",
        "        return key\n",
        "    print(\"Enter your OpenAI API key (input hidden). Press Enter to skip real calls.\")\n",
        "    key = getpass(\"API key: \").strip()\n",
        "    if key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = key\n",
        "        return key\n",
        "    return None\n",
        "\n",
        "OPENAI_CLIENT = None\n",
        "if USE_OPENAI:\n",
        "    if _ensure_openai_key():\n",
        "        try:\n",
        "            OPENAI_CLIENT = OpenAI()                # reads key from env\n",
        "            _ = OPENAI_CLIENT.models.list().data[:1]  # light probe\n",
        "            print(\"✅ OpenAI client ready.\")\n",
        "        except Exception as e:\n",
        "            OPENAI_CLIENT = None\n",
        "            USE_OPENAI = False\n",
        "            print(\"❌ OpenAI init failed, falling back to mock mode:\", type(e).__name__, e)\n",
        "    else:\n",
        "        USE_OPENAI = False\n",
        "        print(\"ℹ️ No key provided — using mock mode.\")\n",
        "else:\n",
        "    print(\"🔒 USE_OPENAI is False — using mock mode (offline).\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "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\n"
      ],
      "metadata": {
        "id": "HOM7fiq7SMfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "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\n"
      ],
      "metadata": {
        "id": "NCLX7kAeSKcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 6.1 clean-up (run once right now) =====\n",
        "import os\n",
        "for k in list(os.environ.keys()):\n",
        "    if k.upper() in {\"OPENAI_API_KEY\", \"OPENAI_ORG_ID\"}:\n",
        "        os.environ.pop(k, None)\n",
        "print(\"✅ Cleared any OPENAI_* env vars from this session. Use Step 6 getpass() to re-auth.\")\n"
      ],
      "metadata": {
        "id": "0zTUEyvpILFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511f5464-6d7d-44a1-bb4c-c462e89e8d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleared any OPENAI_* env vars from this session. Use Step 6 getpass() to re-auth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "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\n"
      ],
      "metadata": {
        "id": "AV2CL_bqCraR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "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\n"
      ],
      "metadata": {
        "id": "h0GfxegWcuXv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB3FLRKUwQAV"
      },
      "source": [
        "# Step 6.2: Ensure NLTK Data is Available\n",
        "\n",
        "\n",
        "###Purpose\n",
        "- Confirm that the required NLTK datasets, particularly the 'punkt' tokenizer,\n",
        "  are available for sentence and word tokenization.\n",
        "- Automatically download them into a local or Colab-safe directory if missing.\n",
        "\n",
        "###What you may need to change\n",
        "- nltk_data_path: set this to a writable directory if running outside Colab\n",
        "  (e.g., './nltk_data' for local use).\n",
        "\n",
        "###Inputs\n",
        "- None (downloads handled internally if needed).\n",
        "\n",
        "###Outputs\n",
        "- Verified or newly downloaded 'punkt' tokenizer package.\n",
        "\n",
        "###Key ideas\n",
        "- NLTK looks for data in a set of known paths; adding a custom directory avoids permission issues.\n",
        "- Downloading into /content/nltk_data keeps notebooks portable and clean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUWxluoWG4ez",
        "outputId": "36727100-b2c9-4c9d-b6fe-046e64aca713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NLTK 'punkt' tokenizer is already available.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ===============================================\n",
        "# Step 6.2: Ensure NLTK Data is Available\n",
        "# ===============================================\n",
        "import nltk, os\n",
        "\n",
        "# Specify a safe directory for NLTK data (works in Colab or local)\n",
        "nltk_data_path = \"/content/nltk_data\" if os.path.exists(\"/content\") else \"./nltk_data\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(nltk_data_path, exist_ok=True)\n",
        "\n",
        "# Ensure our path is part of NLTK’s search list\n",
        "if nltk_data_path not in nltk.data.path:\n",
        "    nltk.data.path.append(nltk_data_path)\n",
        "\n",
        "# Try locating the punkt tokenizer\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt\")\n",
        "    print(\"✅ NLTK 'punkt' tokenizer is already available.\")\n",
        "except LookupError:\n",
        "    print(\"⚙️ Downloading NLTK 'punkt' tokenizer...\")\n",
        "    nltk.download(\"punkt\", download_dir=nltk_data_path)\n",
        "    try:\n",
        "        nltk.data.find(\"tokenizers/punkt\")\n",
        "        print(\"✅ 'punkt' tokenizer downloaded successfully.\")\n",
        "    except LookupError:\n",
        "        print(\"❌ Failed to download 'punkt' tokenizer. Check network or permissions.\")\n",
        "\n",
        "# Optional: newer punkt tokenizer for NLTK ≥ 3.8\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt_tab\")\n",
        "except LookupError:\n",
        "    try:\n",
        "        nltk.download(\"punkt_tab\", download_dir=nltk_data_path)\n",
        "        print(\"✅ 'punkt_tab' (improved tokenizer) also downloaded.\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTZjaIlJwYxy"
      },
      "source": [
        "# Step 7: Define Utility Functions for ChatGPT API Interaction\n",
        "## Purpose:\n",
        "To create reusable functions that handle interactions with the OpenAI API, including making requests with retry mechanisms to handle potential API errors.\n",
        "\n",
        "##Input: Function parameters (things you pass in)\n",
        "\n",
        "-prompt — the text you want the model to read and reply to. Required.\n",
        "\n",
        "-model=\"gpt-4o\" — which model to call if you don’t give one. Default is gpt-4o.For cost:  https://platform.openai.com/settings/organization/limits\n",
        "\n",
        "-max_retries=5 — how many times to try again if the API fails temporarily. Five tries is a common default.\n",
        "\n",
        "-backoff_factor=2 — controls how long to wait between retries. Bigger numbers make you wait longer each retry.\n",
        "\n",
        "-temperature=0 — controls randomness. Zero aims for consistent, repeatable answers.\n",
        "\n",
        "-max_tokens=8192 — the maximum number of tokens you allow the model to output.\n",
        "\n",
        "## Output: Local variables inside the function\n",
        "\n",
        "attempt — which retry number you are on in the loop.\n",
        "\n",
        "response — the raw object the API returns.\n",
        "\n",
        "content — the actual text reply you extract from the response.\n",
        "\n",
        "usage — token usage information (helps with billing and diagnostics).\n",
        "\n",
        "e — the caught exception when something goes wrong.\n",
        "\n",
        "wait — how many seconds the code sleeps before retrying.\n",
        "\n",
        "## Actions:\n",
        "\n",
        "* Define call_chatgpt Function:\n",
        "Parameters: Accepts prompt, model, max_retries, backoff_factor, temperature, and max_tokens.\n",
        "* Functionality: Attempts to call the OpenAI API with exponential backoff in case of failures like rate limits or timeouts.\n",
        "* Error Handling: Catches specific OpenAI errors and retries the request after waiting for a calculated duration.\n",
        "* Returns: The content of the API response or None if all retries fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONQmC4wvtzoD"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# Step 7: Define Utility Functions for ChatGPT API Interaction\n",
        "# ===============================================\n",
        "# ---- v1-safe, timeout + retries, correct exception classes ----\n",
        "import time, random, logging\n",
        "from openai import OpenAI\n",
        "from openai import (\n",
        "    APIError, APIConnectionError, RateLimitError, APITimeoutError,\n",
        "    AuthenticationError\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def _token_len(text, encoder):\n",
        "    try:\n",
        "        return len(encoder.encode(text or \"\"))\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def call_chatgpt_v1(\n",
        "    prompt,\n",
        "    model=\"gpt-4o\",\n",
        "    max_retries=5,\n",
        "    backoff_factor=2.0,\n",
        "    temperature=0.0,\n",
        "    max_tokens=None,\n",
        "    client: OpenAI = None,\n",
        "    token_encoder=None,\n",
        "    model_context_limit=131072,\n",
        "    request_timeout=30  # seconds\n",
        "):\n",
        "    client = client or OpenAI()\n",
        "    # per-request timeout (prevents hanging)\n",
        "    if hasattr(client, \"with_options\"):\n",
        "        client = client.with_options(timeout=request_timeout)\n",
        "\n",
        "    if max_tokens is None and token_encoder is not None:\n",
        "        prompt_toks = _token_len(prompt, token_encoder)\n",
        "        max_tokens = max(256, min(4096, model_context_limit - prompt_toks - 1024))\n",
        "    elif max_tokens is None:\n",
        "        max_tokens = 1024\n",
        "\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=temperature,\n",
        "                max_tokens=max_tokens,\n",
        "            )\n",
        "            content = resp.choices[0].message.content\n",
        "            usage = getattr(resp, \"usage\", {}) or {}\n",
        "            return content, usage\n",
        "\n",
        "        except (RateLimitError, APIConnectionError, APITimeoutError, APIError) as e:\n",
        "            wait = min(60, (backoff_factor ** attempt) + random.uniform(0, 1))\n",
        "            logger.warning(\n",
        "                \"API transient error (attempt %d/%d): %s. Retrying in %.1fs\",\n",
        "                attempt, max_retries, str(e), wait\n",
        "            )\n",
        "            time.sleep(wait)\n",
        "            continue\n",
        "\n",
        "        except AuthenticationError as e:\n",
        "            logger.error(\"Authentication failed: %s\", e)\n",
        "            raise\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            logger.error(\"Interrupted by user. Aborting cleanly.\")\n",
        "            raise\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.exception(\"Unexpected error on attempt %d: %s\", attempt, e)\n",
        "            break\n",
        "\n",
        "    logger.error(\"Max retries exceeded. Returning (None, {}).\")\n",
        "    return None, {}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtofZzoKwscq"
      },
      "source": [
        "# Step 8: Correct Text by Sentence\n",
        "## Purpose:\n",
        "To process raw text by correcting punctuation, grammar, and spelling. Then creating a new field with the corrected text. Also, itm maaps the correctext back to the raw text.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Actions:\n",
        "* Important all helpers and loggers.\n",
        "* Define corrrect_and_mmap Function:\n",
        " * Parameters: Accepts text (the raw input text).\n",
        " * Prompt Creation: Constructs a detailed prompt with instructions for the AI to perform specific tasks on the text: correcting punctuation, grammar, and spelling. Providing bencharks to map corrected to segmented by word.\n",
        " * API Call: Uses the previously defined call_chatgpt function to send the prompt to the OpenAI API.\n",
        " * Response Handling: Extracts JSON from the API response and parses it into a Python dictionary.\n",
        " * Error Handling: Catches JSON decoding errors and returns an empty dictionary if parsing fails.\n",
        "*Mock Text for Testing:\n",
        "at the end, create mock version of correct_and_map is used to simulate API behavior for testing purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DjTMA1gic_yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "assert isinstance(df_preprocessed, pd.DataFrame), \"df_preprocessed is not a DataFrame\"\n",
        "assert \"ID\" in df_preprocessed.columns, \"Missing 'ID' column in df_preprocessed\"\n",
        "assert \"Raw text\" in df_preprocessed.columns, \"Missing 'Raw text' column in df_preprocessed\"\n",
        "\n",
        "print(\"First IDs:\", df_preprocessed[\"ID\"].head().tolist())\n",
        "print(\"Columns:\", list(df_preprocessed.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQoArp96HE5T",
        "outputId": "704fd30a-926b-4286-e1da-3037afacd735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First IDs: ['BBCMHJPT', 'BBKBYNDW', 'BBRWTLYV', 'BCDVWQDF', 'BCXSFTWC']\n",
            "Columns: ['ID', 'Research ID', 'AU', 'TS', 'IdeaID', 'CS/PD', 'Voc', 'Coh', 'Pa', 'SS', 'Pun', 'Spell', 'Total', 'WordCount', 'yrlev', 'Raw text', 'TokenCount']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZjuniJ3cHdUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Step 8 — enforce canonical ID at the top\n",
        "# ===============================================\n",
        "def run_correct_only(\n",
        "    df_in: pd.DataFrame,\n",
        "    text_col=\"Raw text\",\n",
        "    id_col=\"ID\",\n",
        "    client=None,\n",
        "    model=\"gpt-4o\",\n",
        "    use_mock=False,\n",
        "    out_col=\"Corrected text (8)\"\n",
        ") -> pd.DataFrame:\n",
        "    if text_col not in df_in.columns:\n",
        "        raise KeyError(f\"Missing required column: '{text_col}'\")\n",
        "    df, _src = ensure_canonical_id(df_in, canon=id_col)\n",
        "    # proceed as before (unchanged body below) …\n",
        "    corrected, tags_json, dlg_json, sources = [], [], [], []\n",
        "    for raw in df[text_col].astype(str).tolist():\n",
        "        c, tags, spans, src = correct_with_tags(raw, client=client, model=model, use_mock=use_mock)\n",
        "        corrected.append(c)\n",
        "        tags_json.append(json.dumps(tags, ensure_ascii=False))\n",
        "        dlg_json.append(json.dumps(spans, ensure_ascii=False))\n",
        "        sources.append(src)\n",
        "    df[out_col] = corrected\n",
        "    df[\"NarrativeTagsJSON\"] = tags_json\n",
        "    df[\"DialogueSpansJSON\"]  = dlg_json\n",
        "    df[\"CorrectedBy\"]        = sources\n",
        "    return df\n",
        "\n",
        "def run_step8(df_preprocessed: pd.DataFrame,\n",
        "              raw_col=\"Raw text\",\n",
        "              id_col=\"ID\",\n",
        "              client=None,\n",
        "              model=\"gpt-4o\",\n",
        "              use_mock=False):\n",
        "    # Normalize ID once at the very top\n",
        "    df_pre, id_src = ensure_canonical_id(df_preprocessed, canon=id_col)\n",
        "    print(f\"▶️  Step 8 using ID source: {id_src}\")\n",
        "\n",
        "    # 8A\n",
        "    df_corr = run_correct_only(\n",
        "        df_pre, text_col=raw_col, id_col=id_col,\n",
        "        client=None if use_mock else client, model=model, use_mock=use_mock,\n",
        "        out_col=\"Corrected text (8)\"\n",
        "    )\n",
        "    df_corr[\"Corrected text (8)\"] = df_corr[\"Corrected text (8)\"].map(normalize_mojibake)\n",
        "\n",
        "    # 8B\n",
        "    df_map, df_texts = run_mapping_only(df_corr, id_col=id_col, raw_col=raw_col, corr_col=\"Corrected text (8)\")\n",
        "\n",
        "    # 8R → 8C → 8D → 8E (unchanged body)\n",
        "    df_map = smart_repair_alignment(df_map, window=6, sim_word=0.60, sim_join=0.72)\n",
        "    df_map = assign_corr_sentence_ids(df_map)\n",
        "    df_texts[\"ID\"] = df_texts[\"ID\"].astype(str)\n",
        "    df_map = mark_title_tokens(df_map, df_texts_with_tags=df_texts)\n",
        "    df_map = add_sentence_boundary_flags(df_map)\n",
        "    return df_texts, df_map\n",
        "\n"
      ],
      "metadata": {
        "id": "JPiBiKkdVWe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8A — Correct text + detect tags (LLM or mock) — Doc ID = `ID`, Idea key optional as `IdeaID`\n",
        "# What this does:\n",
        "# • Uses the canonical document ID in column `ID` (already set from \"Research ID\" in Step 2A).\n",
        "# • Leaves any existing idea-level key in `IdeaID` untouched.\n",
        "# • For each \"Raw text\", produces:\n",
        "#     - \"Corrected text (8)\"\n",
        "#     - \"NarrativeTagsJSON\" (title / temporal / closure with char spans on corrected text)\n",
        "#     - \"DialogueSpansJSON\" (quoted speech spans on corrected text)\n",
        "#     - \"CorrectedBy\" (mock, model name, or 'error')\n",
        "# ===============================\n",
        "\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- helpers ---\n",
        "\n",
        "def _normalize_id_series(s: pd.Series) -> pd.Series:\n",
        "    \"\"\"Return all IDs as clean strings (no .0, no float drift).\"\"\"\n",
        "    s = s.astype(str).str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "    def _fix(x):\n",
        "        if any(c.isalpha() for c in x):\n",
        "            return x\n",
        "        try:\n",
        "            if \".\" in x or \"e\" in x.lower():\n",
        "                f = float(x)\n",
        "                if f.is_integer():\n",
        "                    return str(int(f))\n",
        "        except Exception:\n",
        "            pass\n",
        "        return x\n",
        "    return s.map(_fix)\n",
        "\n",
        "# Basic text normalizer (safe to re-declare if Step 2 cell didn't run here)\n",
        "try:\n",
        "    normalize_mojibake\n",
        "except NameError:\n",
        "    def normalize_mojibake(s: str) -> str:\n",
        "        if s is None:\n",
        "            return \"\"\n",
        "        s = str(s)\n",
        "        fixes = {\n",
        "            \"â€”\": \"—\", \"â€“\": \"–\",\n",
        "            \"â€˜\": \"‘\", \"â€™\": \"’\",\n",
        "            \"â€œ\": \"“\", \"â€\\x9d\": \"”\", \"â€\\x9c\": \"“\",\n",
        "            \"â€¦\": \"…\", \"â€¢\": \"•\", \"â€\": \"”\",\n",
        "        }\n",
        "        for bad, good in fixes.items():\n",
        "            s = s.replace(bad, good)\n",
        "        return re.sub(r\"[ \\t\\u00A0\\u2007\\u202F]+\", \" \", s).strip()\n",
        "\n",
        "def _extract_first_json_object(txt: str):\n",
        "    \"\"\"Find the first {...} JSON object in a string.\"\"\"\n",
        "    if not txt:\n",
        "        return None\n",
        "    start = txt.find(\"{\")\n",
        "    if start < 0:\n",
        "        return None\n",
        "    depth, in_str, esc = 0, False, False\n",
        "    for i in range(start, len(txt)):\n",
        "        ch = txt[i]\n",
        "        if in_str:\n",
        "            if esc: esc = False\n",
        "            elif ch == \"\\\\\": esc = True\n",
        "            elif ch == '\"': in_str = False\n",
        "        else:\n",
        "            if ch == '\"': in_str = True\n",
        "            elif ch == \"{\": depth += 1\n",
        "            elif ch == \"}\":\n",
        "                depth -= 1\n",
        "                if depth == 0:\n",
        "                    frag = txt[start:i+1]\n",
        "                    try:\n",
        "                        return json.loads(frag)\n",
        "                    except Exception:\n",
        "                        return None\n",
        "    return None\n",
        "\n",
        "def correct_with_tags(raw: str, client=None, model=\"gpt-4o\", use_mock=False, max_tokens=1500):\n",
        "    \"\"\"\n",
        "    Return: corrected_text, narrative_tags(list), dialogue_spans(list), source_label.\n",
        "    If use_mock=True or client is None, returns a simple deterministic correction.\n",
        "    \"\"\"\n",
        "    s = normalize_mojibake(str(raw or \"\")).strip()\n",
        "\n",
        "    if use_mock or client is None:\n",
        "        # Mock: capitalise first letter; ensure terminal punctuation\n",
        "        t = s\n",
        "        m = re.search(r\"[A-Za-z]\", t)\n",
        "        if m:\n",
        "            i = m.start()\n",
        "            t = t[:i] + t[i].upper() + t[i+1:]\n",
        "        if t and not re.search(r\"[.!?…]\\s*$\", t):\n",
        "            t += \".\"\n",
        "        return t, [], [], \"mock\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a careful copy-editor. Fix punctuation, grammar, and spelling.\n",
        "Keep meaning and paragraphing. Use standard English punctuation.\n",
        "\n",
        "Also detect:\n",
        "- Titles at the very start: type=\"title\"\n",
        "- Temporal transitions: type=\"temporal\" (e.g., \"The next day\", dates)\n",
        "- Closures: type=\"closure\" (e.g., \"THE END\")\n",
        "Provide character indices [start,end) on the corrected text.\n",
        "\n",
        "Also return dialogue spans (quoted direct speech) as {{start,end}}.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{{\n",
        "  \"corrected_text\": \"...\",\n",
        "  \"narrative_tags\": [{{\"type\":\"title|temporal|closure\",\"text\":\"...\",\"start\":int,\"end\":int}}, ...],\n",
        "  \"dialogue_spans\": [{{\"start\":int,\"end\":int}}, ...]\n",
        "}}\n",
        "\n",
        "Text:\n",
        "<<<BEGIN>>>\n",
        "{s}\n",
        "<<<END>>>\n",
        "\"\"\".strip()\n",
        "\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        _client = client or OpenAI()\n",
        "        resp = _client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "            temperature=0.0,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        out = (resp.choices[0].message.content or \"\").strip()\n",
        "        js = _extract_first_json_object(out)\n",
        "        if not isinstance(js, dict):\n",
        "            return s, [], [], \"fallback\"\n",
        "\n",
        "        corrected = normalize_mojibake(js.get(\"corrected_text\",\"\") or \"\").strip()\n",
        "        N = len(corrected)\n",
        "\n",
        "        def _clean_tags(tags):\n",
        "            clean = []\n",
        "            for t in tags or []:\n",
        "                try:\n",
        "                    tt = str(t.get(\"type\",\"\")).lower()\n",
        "                    st = max(0, int(t.get(\"start\",0)))\n",
        "                    en = max(st, int(t.get(\"end\",0)))\n",
        "                    st = min(st, N); en = min(en, N)\n",
        "                    if tt in {\"title\",\"temporal\",\"closure\"} and en > st:\n",
        "                        clean.append({\"type\":tt,\"text\":corrected[st:en],\"start\":st,\"end\":en})\n",
        "                except Exception:\n",
        "                    pass\n",
        "            return clean\n",
        "\n",
        "        def _clean_spans(spans):\n",
        "            clean = []\n",
        "            for d in spans or []:\n",
        "                try:\n",
        "                    st = max(0, int(d.get(\"start\",0)))\n",
        "                    en = max(st, int(d.get(\"end\",0)))\n",
        "                    st = min(st, N); en = min(en, N)\n",
        "                    if en > st:\n",
        "                        clean.append({\"start\":st,\"end\":en})\n",
        "                except Exception:\n",
        "                    pass\n",
        "            return clean\n",
        "\n",
        "        return corrected, _clean_tags(js.get(\"narrative_tags\")), _clean_spans(js.get(\"dialogue_spans\")), model\n",
        "    except Exception as e:\n",
        "        logger.warning(\"LLM correction failed. Using normalized raw. %s\", e)\n",
        "        return s, [], [], \"error\"\n",
        "\n",
        "def run_correct_only(\n",
        "    df_in: pd.DataFrame,\n",
        "    text_col=\"Raw text\",\n",
        "    id_col=\"ID\",           # canonical DOC ID (from Research ID in Step 2A)\n",
        "    client=None,\n",
        "    model=\"gpt-4o\",\n",
        "    use_mock=False,\n",
        "    out_col=\"Corrected text (8)\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Apply correction + tagging row by row and return a new dataframe.\n",
        "    Assumes df_in[id_col] already holds canonical document IDs.\n",
        "    Preserves IdeaID if present; does not rename ID columns here.\n",
        "    \"\"\"\n",
        "    need = {text_col, id_col}\n",
        "    miss = need - set(df_in.columns)\n",
        "    if miss:\n",
        "        raise KeyError(f\"Missing required columns for 8A: {sorted(miss)}\")\n",
        "\n",
        "    df = df_in.copy()\n",
        "    # Normalise the canonical doc ID column to stable string form\n",
        "    df[id_col] = _normalize_id_series(df[id_col])\n",
        "\n",
        "    corrected, tags_json, dlg_json, sources = [], [], [], []\n",
        "\n",
        "    # Iterate texts deterministically in current order\n",
        "    for raw in df[text_col].astype(str).tolist():\n",
        "        c, tags, spans, src = correct_with_tags(\n",
        "            raw, client=client, model=model, use_mock=use_mock\n",
        "        )\n",
        "        corrected.append(c)\n",
        "        tags_json.append(json.dumps(tags, ensure_ascii=False))\n",
        "        dlg_json.append(json.dumps(spans, ensure_ascii=False))\n",
        "        sources.append(src)\n",
        "\n",
        "    df[out_col] = corrected\n",
        "    df[\"NarrativeTagsJSON\"] = tags_json\n",
        "    df[\"DialogueSpansJSON\"]  = dlg_json\n",
        "    df[\"CorrectedBy\"]        = sources\n",
        "\n",
        "    # No column shuffling or renaming here—ID/IdeaID remain as passed in.\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "WuZg_-kFJunn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8B — Tokenize, align, and build a word-level map\n",
        "# What this does:\n",
        "# • Splits raw and corrected into tokens.\n",
        "# • Rebuilds character offsets for each token.\n",
        "# • Diffs tokens to label equal, insert, delete, replace.\n",
        "# • Produces a long table (one row per token alignment).\n",
        "# Inputs:  df with [\"ID\",\"Raw text\",\"Corrected text (8)\"]\n",
        "# Outputs: map_df (long table), texts_out (pass through of the texts)\n",
        "# ===============================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "_WORD_RX = re.compile(r\"\\w\", flags=re.UNICODE)\n",
        "\n",
        "def _split_merged_word(tok: str):\n",
        "    # Split once when ALLCAPS is followed by lowercase: YAAYwe -> YAAY + we\n",
        "    if not tok or not tok.isalpha():\n",
        "        return [tok]\n",
        "    m = re.match(r\"^([A-Z]{2,})([a-z].*)$\", tok)\n",
        "    if m:\n",
        "        left, right = m.group(1), m.group(2)\n",
        "        return [left, right]\n",
        "    return [tok]\n",
        "\n",
        "def _tokenize_with_split(s: str):\n",
        "    base = re.findall(r\"\\w+|[^\\w\\s]\", s or \"\", flags=re.UNICODE)\n",
        "    out = []\n",
        "    for t in base:\n",
        "        if re.fullmatch(r\"\\w+\", t):\n",
        "            out.extend(_split_merged_word(t))\n",
        "        else:\n",
        "            out.append(t)\n",
        "    return out\n",
        "\n",
        "def _rebuild_offsets_with_splitting(text, tokens):\n",
        "    \"\"\"Find each token's start and end index in the original string, with safe clamping.\"\"\"\n",
        "    text = text or \"\"\n",
        "    spans, i, n = [], 0, len(text)\n",
        "    for tok in tokens:\n",
        "        if tok == \"\" or tok is None:\n",
        "            spans.append((i, i))\n",
        "            continue\n",
        "        pos = text.find(tok, i)\n",
        "        if pos >= 0:\n",
        "            start, end = pos, pos + len(tok)\n",
        "        else:\n",
        "            j = i\n",
        "            while j < n and text[j].isspace():\n",
        "                j += 1\n",
        "            start = j\n",
        "            end = start + len(tok)\n",
        "        start = max(0, min(start, n))\n",
        "        end   = max(start, min(end, n))\n",
        "        spans.append((start, end))\n",
        "        i = end\n",
        "    return spans\n",
        "\n",
        "def _is_word(tok: str) -> bool:\n",
        "    return bool(tok) and bool(_WORD_RX.search(tok))\n",
        "\n",
        "def _canon(tok: str) -> str:\n",
        "    \"\"\"Canonical form for diff: uppercase and collapse repeated letters.\"\"\"\n",
        "    if tok is None:\n",
        "        return \"\"\n",
        "    u = str(tok).upper()\n",
        "    return re.sub(r\"(.)\\1+\", r\"\\1\", u)\n",
        "\n",
        "def build_word_map(raw_text, corr_text):\n",
        "    raw_text  = str(raw_text or \"\")\n",
        "    corr_text = str(corr_text or \"\")\n",
        "\n",
        "    raw_tokens  = _tokenize_with_split(raw_text)\n",
        "    corr_tokens = _tokenize_with_split(corr_text)\n",
        "\n",
        "    raw_spans  = _rebuild_offsets_with_splitting(raw_text, raw_tokens)\n",
        "    corr_spans = _rebuild_offsets_with_splitting(corr_text, corr_tokens)\n",
        "\n",
        "    sm = SequenceMatcher(a=[_canon(t) for t in raw_tokens],\n",
        "                         b=[_canon(t) for t in corr_tokens],\n",
        "                         autojunk=False)\n",
        "\n",
        "    rows = []\n",
        "    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
        "        if tag == \"equal\":\n",
        "            for k in range(i2 - i1):\n",
        "                ri = i1 + k; ci = j1 + k\n",
        "                r_tok, c_tok = raw_tokens[ri], corr_tokens[ci]\n",
        "                r_start, r_end = raw_spans[ri]\n",
        "                c_start, c_end = corr_spans[ci]\n",
        "                rows.append({\n",
        "                    \"raw_index\": ri, \"raw_token\": r_tok, \"raw_start\": r_start, \"raw_end\": r_end,\n",
        "                    \"corr_index\": ci, \"corr_token\": c_tok, \"corr_start\": c_start, \"corr_end\": c_end,\n",
        "                    \"op\": \"equal\", \"equal_ci\": (r_tok == c_tok), \"error_type\": \"Equal\"\n",
        "                })\n",
        "\n",
        "        elif tag == \"replace\":\n",
        "            m = min(i2 - i1, j2 - j1)\n",
        "            for k in range(m):\n",
        "                ri = i1 + k; ci = j1 + k\n",
        "                r_tok, c_tok = raw_tokens[ri], corr_tokens[ci]\n",
        "                r_start, r_end = raw_spans[ri]\n",
        "                c_start, c_end = corr_spans[ci]\n",
        "                err = \"Spelling\" if (str(r_tok).isalpha() and str(c_tok).isalpha() and _canon(r_tok) == _canon(c_tok)) else \"Replacement\"\n",
        "                rows.append({\n",
        "                    \"raw_index\": ri, \"raw_token\": r_tok, \"raw_start\": r_start, \"raw_end\": r_end,\n",
        "                    \"corr_index\": ci, \"corr_token\": c_tok, \"corr_start\": c_start, \"corr_end\": c_end,\n",
        "                    \"op\": \"replace\", \"equal_ci\": (_canon(r_tok) == _canon(c_tok)), \"error_type\": err\n",
        "                })\n",
        "            for ri in range(i1 + m, i2):\n",
        "                r_tok = raw_tokens[ri]; r_start, r_end = raw_spans[ri]\n",
        "                rows.append({\n",
        "                    \"raw_index\": ri, \"raw_token\": r_tok, \"raw_start\": r_start, \"raw_end\": r_end,\n",
        "                    \"corr_index\": None, \"corr_token\": None, \"corr_start\": None, \"corr_end\": None,\n",
        "                    \"op\": \"delete\", \"equal_ci\": False,\n",
        "                    \"error_type\": \"PunctuationDeletion\" if not _is_word(r_tok) else \"Deletion\"\n",
        "                })\n",
        "            for ci in range(j1 + m, j2):\n",
        "                c_tok = corr_tokens[ci]; c_start, c_end = corr_spans[ci]\n",
        "                rows.append({\n",
        "                    \"raw_index\": None, \"raw_token\": None, \"raw_start\": None, \"raw_end\": None,\n",
        "                    \"corr_index\": ci, \"corr_token\": c_tok, \"corr_start\": c_start, \"corr_end\": c_end,\n",
        "                    \"op\": \"insert\", \"equal_ci\": False,\n",
        "                    \"error_type\": \"PunctuationInsertion\" if not _is_word(c_tok) else \"Insertion\"\n",
        "                })\n",
        "\n",
        "        elif tag == \"delete\":\n",
        "            for ri in range(i1, i2):\n",
        "                r_tok = raw_tokens[ri]; r_start, r_end = raw_spans[ri]\n",
        "                rows.append({\n",
        "                    \"raw_index\": ri, \"raw_token\": r_tok, \"raw_start\": r_start, \"raw_end\": r_end,\n",
        "                    \"corr_index\": None, \"corr_token\": None, \"corr_start\": None, \"corr_end\": None,\n",
        "                    \"op\": \"delete\", \"equal_ci\": False,\n",
        "                    \"error_type\": \"PunctuationDeletion\" if not _is_word(r_tok) else \"Deletion\"\n",
        "                })\n",
        "\n",
        "        elif tag == \"insert\":\n",
        "            for ci in range(j1, j2):\n",
        "                c_tok = corr_tokens[ci]; c_start, c_end = corr_spans[ci]\n",
        "                rows.append({\n",
        "                    \"raw_index\": None, \"raw_token\": None, \"raw_start\": None, \"raw_end\": None,\n",
        "                    \"corr_index\": ci, \"corr_token\": c_tok, \"corr_start\": c_start, \"corr_end\": c_end,\n",
        "                    \"op\": \"insert\", \"equal_ci\": False,\n",
        "                    \"error_type\": \"PunctuationInsertion\" if not _is_word(c_tok) else \"Insertion\"\n",
        "                })\n",
        "    return rows\n",
        "\n",
        "def run_mapping_only(df_with_corr,\n",
        "                     id_col=\"ID\",\n",
        "                     raw_col=\"Raw text\",\n",
        "                     corr_col=\"Corrected text (8)\"):\n",
        "    \"\"\"Build the long alignment table.\"\"\"\n",
        "    need = {raw_col, corr_col}\n",
        "    if not need.issubset(df_with_corr.columns):\n",
        "        raise KeyError(f\"Missing columns: {need - set(df_with_corr.columns)}\")\n",
        "    df = df_with_corr.copy()\n",
        "    if id_col not in df.columns:\n",
        "        df[id_col] = pd.RangeIndex(len(df)).astype(str)\n",
        "    df[id_col] = df[id_col].astype(str)\n",
        "\n",
        "    all_rows = []\n",
        "    for order, (rid, raw, cor) in enumerate(zip(\n",
        "        df[id_col].tolist(),\n",
        "        df[raw_col].astype(str).tolist(),\n",
        "        df[corr_col].astype(str).tolist()\n",
        "    )):\n",
        "        rows = build_word_map(raw, cor)\n",
        "        if not rows:\n",
        "            rows = [{\n",
        "                \"raw_index\": np.nan, \"raw_token\": None, \"raw_start\": np.nan, \"raw_end\": np.nan,\n",
        "                \"corr_index\": np.nan, \"corr_token\": None, \"corr_start\": np.nan, \"corr_end\": np.nan,\n",
        "                \"op\": \"empty\", \"equal_ci\": False, \"error_type\": \"EmptyText\"\n",
        "            }]\n",
        "        for r in rows:\n",
        "            rec = {\"RowID\": rid, \"DocOrder\": order, **r}\n",
        "            rec[\"Changed\"] = (r.get(\"op\") != \"equal\")\n",
        "            all_rows.append(rec)\n",
        "    map_df = pd.DataFrame(all_rows)\n",
        "    texts_out = df.copy()\n",
        "    return map_df, texts_out\n"
      ],
      "metadata": {
        "id": "a0YOPBYKBvIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8R — Smart alignment repair to fix replace+insert anomalies\n",
        "# What this does:\n",
        "# • Collapses bad patterns like:\n",
        "#     \"lest\" -> \"Let\" + inserted \".\"  into a single word replacement where appropriate\n",
        "#     \"im\"   -> \"I\" + \"'\" + \"m\" into \"I'm\"\n",
        "# • Reduces false \"Incorrect Beginning/Ending\" flags that come from stray punctuation inserts\n",
        "# Inputs:  df_map from 8B\n",
        "# Output:  repaired df_map\n",
        "# ===============================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def _jw(a, b):\n",
        "    return SequenceMatcher(None, str(a), str(b)).ratio()\n",
        "\n",
        "def _letters_only(s):\n",
        "    return re.sub(r\"[^A-Za-z]+\", \"\", str(s or \"\"))\n",
        "\n",
        "def _is_wordish(tok):\n",
        "    t = str(tok or \"\")\n",
        "    return bool(re.search(r\"\\w\", t)) and not re.fullmatch(r\"[\\W_]+\", t)\n",
        "\n",
        "def smart_repair_alignment(df_map: pd.DataFrame,\n",
        "                           window=6,\n",
        "                           sim_word=0.60,\n",
        "                           sim_join=0.72) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Two repairs:\n",
        "      1) punctuation-word swap:\n",
        "         replace(raw_word -> punct) + insert(correct_word) => single replace(raw_word -> correct_word)\n",
        "      2) split-to-multiple inserts:\n",
        "         im -> I ' m  or  tack -> t a k e (rare) => join inserts to \"I'm\" or \"take\"\n",
        "    \"\"\"\n",
        "    if df_map.empty:\n",
        "        return df_map.copy()\n",
        "\n",
        "    df = df_map.copy()\n",
        "    if \"ID\" not in df.columns:\n",
        "        df[\"ID\"] = df[\"RowID\"].astype(str)\n",
        "\n",
        "    df[\"_rowpos\"] = np.arange(len(df))\n",
        "    if \"corr_index\" in df.columns:\n",
        "        df[\"_sort\"] = pd.to_numeric(df[\"corr_index\"], errors=\"coerce\").fillna(1e12) + df[\"_rowpos\"]*1e-9\n",
        "    else:\n",
        "        df[\"_sort\"] = df[\"_rowpos\"]\n",
        "\n",
        "    chunks = []\n",
        "    for gid, g in df.sort_values([\"ID\",\"_sort\"], kind=\"mergesort\").groupby(\"ID\", sort=False):\n",
        "        g = g.copy()\n",
        "        idxs = list(g.index)\n",
        "\n",
        "        # pass 1: punctuation-word swap\n",
        "        to_drop = set()\n",
        "        for k, i in enumerate(idxs):\n",
        "            if i in to_drop:\n",
        "                continue\n",
        "            if g.at[i, \"op\"] != \"replace\":\n",
        "                continue\n",
        "            r_tok = g.at[i, \"raw_token\"]\n",
        "            c_tok = g.at[i, \"corr_token\"]\n",
        "            if _is_wordish(r_tok) and not _is_wordish(c_tok):\n",
        "                for j in idxs[k+1 : k+1+window]:\n",
        "                    if g.at[j, \"op\"] != \"insert\":\n",
        "                        continue\n",
        "                    ins_tok = g.at[j, \"corr_token\"]\n",
        "                    if not _is_wordish(ins_tok):\n",
        "                        continue\n",
        "                    sim = _jw(_letters_only(r_tok).lower(), _letters_only(ins_tok).lower())\n",
        "                    if sim >= sim_word:\n",
        "                        g.at[i, \"corr_token\"] = ins_tok\n",
        "                        g.at[i, \"corr_index\"] = g.at[j, \"corr_index\"]\n",
        "                        g.at[i, \"corr_start\"] = g.at[j, \"corr_start\"]\n",
        "                        g.at[i, \"corr_end\"]   = g.at[j, \"corr_end\"]\n",
        "                        g.at[i, \"error_type\"] = \"Replacement\"\n",
        "                        to_drop.add(j)\n",
        "                        break\n",
        "\n",
        "        if to_drop:\n",
        "            g = g.drop(index=list(to_drop))\n",
        "            idxs = list(g.index)\n",
        "\n",
        "        # pass 2: merge multiple inserts into one replacement when they match the raw word\n",
        "        to_drop = set()\n",
        "        for k, i in enumerate(idxs):\n",
        "            if i in to_drop:\n",
        "                continue\n",
        "            if g.at[i, \"op\"] not in (\"replace\", \"delete\"):\n",
        "                continue\n",
        "\n",
        "            r_tok = str(g.at[i, \"raw_token\"] or \"\")\n",
        "            if not _is_wordish(r_tok):\n",
        "                continue\n",
        "\n",
        "            run = []\n",
        "            for j in idxs[k+1 : k+1+window]:\n",
        "                if g.at[j, \"op\"] != \"insert\":\n",
        "                    break\n",
        "                run.append(j)\n",
        "            if not run:\n",
        "                continue\n",
        "\n",
        "            inserted = [str(g.at[j, \"corr_token\"] or \"\") for j in run]\n",
        "            joined_letters = _letters_only(\"\".join(inserted))\n",
        "            raw_letters = _letters_only(r_tok)\n",
        "            if not raw_letters:\n",
        "                continue\n",
        "\n",
        "            sim = _jw(raw_letters.lower(), joined_letters.lower())\n",
        "            if sim >= sim_join:\n",
        "                display_join = re.sub(r\"\\s+\", \"\", \"\".join(inserted))\n",
        "                g.at[i, \"op\"] = \"replace\"\n",
        "                g.at[i, \"corr_token\"] = display_join\n",
        "                g.at[i, \"error_type\"] = \"Replacement\"\n",
        "                g.at[i, \"equal_ci\"] = (raw_letters.lower() == joined_letters.lower())\n",
        "\n",
        "                first = run[0]\n",
        "                last  = run[-1]\n",
        "                g.at[i, \"corr_index\"] = g.at[first, \"corr_index\"]\n",
        "                g.at[i, \"corr_start\"] = g.at[first, \"corr_start\"]\n",
        "                g.at[i, \"corr_end\"]   = g.at[last,  \"corr_end\"]\n",
        "\n",
        "                to_drop.update(run)\n",
        "\n",
        "        if to_drop:\n",
        "            g = g.drop(index=list(to_drop))\n",
        "\n",
        "        chunks.append(g)\n",
        "\n",
        "    out = pd.concat(chunks, axis=0).sort_values([\"ID\",\"_sort\"], kind=\"mergesort\")\n",
        "    return out.drop(columns=[\"_rowpos\",\"_sort\"], errors=\"ignore\")\n"
      ],
      "metadata": {
        "id": "SKTIy8dDBr-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8C — Assign sentence IDs on corrected text\n",
        "# What this does:\n",
        "# • Walks corrected tokens and decides sentence boundaries.\n",
        "# • Handles ellipses and quotes carefully.\n",
        "# • Produces CorrSentenceID per token and a \"SentenceRef\" later.\n",
        "# Inputs:  df_map from 8B/8R\n",
        "# Output:  df_map with CorrSentenceID\n",
        "# ===============================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ABBREV = {\n",
        "    \"mr.\",\"mrs.\",\"ms.\",\"dr.\",\"prof.\",\"sr.\",\"jr.\",\"st.\",\"vs.\",\"etc.\",\n",
        "    \"e.g.\",\"i.e.\",\"cf.\",\"fig.\",\"ex.\",\"no.\",\"approx.\",\"circa.\",\"ca.\",\n",
        "    \"dept.\",\"est.\",\"misc.\",\"rev.\",\"jan.\",\"feb.\",\"mar.\",\"apr.\",\"jun.\",\n",
        "    \"jul.\",\"aug.\",\"sep.\",\"sept.\",\"oct.\",\"nov.\",\"dec.\"\n",
        "}\n",
        "TERMINALS = {\".\", \"!\", \"?\", \"…\", \"...\", \"?!\", \"!?\"}\n",
        "CLOSERS   = {\")\", \"]\", \"}\", \"”\", \"’\", \"»\"}\n",
        "OPENERS   = {\"(\", \"[\", \"{\", \"“\", \"‘\", \"«\"}\n",
        "RE_INITIAL       = re.compile(r\"^[A-Z]\\.$\")\n",
        "RE_INITIAL_PAIR  = re.compile(r\"^[A-Z]\\.[A-Z]\\.$\")\n",
        "RE_NUM_WITH_DOT  = re.compile(r\"^\\d+\\.$\")\n",
        "RE_SECTION_NUM   = re.compile(r\"^\\d+(?:\\.\\d+){1,3}$\")\n",
        "RE_DOT_TAIL      = re.compile(r\"^\\.\\d+$\")\n",
        "RE_ELLIPSIS      = re.compile(r\"^\\.\\.\\.$\")\n",
        "RE_ALPHA_PAREN   = re.compile(r\"^[A-Za-z]\\)$\")\n",
        "\n",
        "def _tok(x):\n",
        "    if pd.isna(x) or x is None: return \"\"\n",
        "    return str(x)\n",
        "\n",
        "def _is_ellipsis_triplet(i, toks):\n",
        "    return (i+2 < len(toks) and toks[i] == \".\" and toks[i+1] == \".\" and toks[i+2] == \".\")\n",
        "\n",
        "def _is_terminal_token(tok: str, prev_tok: str, next_tok: str) -> bool:\n",
        "    t = tok.strip()\n",
        "    if not t:\n",
        "        return False\n",
        "    if t in {\"…\",\"...\"} or RE_ELLIPSIS.fullmatch(t):\n",
        "        return True\n",
        "    if t in {\"?!\",\"!?\"}:\n",
        "        return True\n",
        "    if t in {\"!\",\"?\"}:\n",
        "        return True\n",
        "    if t == \".\":\n",
        "        p = (prev_tok or \"\").strip()\n",
        "        n = (next_tok or \"\").strip()\n",
        "        low_prev = p.lower()\n",
        "        if low_prev in ABBREV: return False\n",
        "        if RE_INITIAL.fullmatch(p) or RE_INITIAL_PAIR.fullmatch(p): return False\n",
        "        if RE_SECTION_NUM.fullmatch(p): return False\n",
        "        if RE_NUM_WITH_DOT.fullmatch(p) and (n and re.match(r\"[A-Za-z(“\\\"'\\[]\", n)): return False\n",
        "        if RE_DOT_TAIL.fullmatch(n): return False\n",
        "        if n.isdigit(): return False\n",
        "        return True\n",
        "    if t == \")\" and RE_ALPHA_PAREN.fullmatch(prev_tok):\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "def _likely_ascii_opening(prev_tok: str, next_tok: str) -> bool:\n",
        "    prev = (prev_tok or \"\").strip()\n",
        "    nxt  = (next_tok or \"\").strip()\n",
        "    if prev == \"\" or prev in TERMINALS or prev in OPENERS:\n",
        "        return True\n",
        "    if nxt and nxt not in TERMINALS and nxt not in CLOSERS:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def assign_corr_sentence_ids(df_map: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df_map.copy()\n",
        "    if \"RowID\" in df.columns and \"ID\" not in df.columns:\n",
        "        df[\"ID\"] = df[\"RowID\"].astype(str)\n",
        "\n",
        "    has_ci = \"corr_index\" in df.columns\n",
        "    if has_ci and \"corr_index_orig\" not in df.columns:\n",
        "        df[\"corr_index_orig\"] = df[\"corr_index\"]\n",
        "\n",
        "    def _stable_sort_key(g: pd.DataFrame) -> pd.Series:\n",
        "        pos = pd.Series(np.arange(len(g)), index=g.index, dtype=float)\n",
        "        if has_ci:\n",
        "            ci = pd.to_numeric(g[\"corr_index\"], errors=\"coerce\")\n",
        "            nan_mask = ci.isna()\n",
        "            bump = (pos - pos.min()) / max((pos.max() - pos.min()), 1) * 1e-6\n",
        "            return ci.where(~nan_mask, 1e9) + bump\n",
        "        return pos\n",
        "\n",
        "    df[\"_sort_key\"] = df.groupby(\"ID\", group_keys=False).apply(_stable_sort_key, include_groups=False)\n",
        "\n",
        "    def _assign(g: pd.DataFrame) -> pd.Series:\n",
        "        g = g.sort_values(\"_sort_key\", kind=\"mergesort\")\n",
        "        toks = (g[\"corr_token\"] if \"corr_token\" in g.columns else g[\"raw_token\"]).map(_tok).tolist()\n",
        "\n",
        "        sids = []\n",
        "        sent_id = 0\n",
        "        pending_end = False\n",
        "        i = 0\n",
        "        while i < len(toks):\n",
        "            tok = toks[i].strip()\n",
        "            prev_tok = toks[i-1].strip() if i > 0 else \"\"\n",
        "            next_tok = toks[i+1].strip() if i+1 < len(toks) else \"\"\n",
        "\n",
        "            if _is_ellipsis_triplet(i, toks):\n",
        "                pending_end = True\n",
        "                sids.append(sent_id)\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            if pending_end:\n",
        "                if tok in CLOSERS or (tok == '\"' and not _likely_ascii_opening(prev_tok, next_tok)):\n",
        "                    sids.append(sent_id); i += 1; continue\n",
        "                if tok in OPENERS or (tok == '\"' and _likely_ascii_opening(prev_tok, next_tok)):\n",
        "                    sent_id += 1; pending_end = False; sids.append(sent_id); i += 1; continue\n",
        "                sent_id += 1; pending_end = False; sids.append(sent_id); i += 1; continue\n",
        "            else:\n",
        "                sids.append(sent_id); i += 1\n",
        "\n",
        "            if _is_terminal_token(tok, prev_tok, next_tok):\n",
        "                pending_end = True\n",
        "\n",
        "        return pd.Series(sids, index=g.index).reindex(g.index)\n",
        "\n",
        "    df[\"CorrSentenceID\"] = (\n",
        "        df.groupby(\"ID\", group_keys=False).apply(_assign, include_groups=False).astype(\"Int64\")\n",
        "    )\n",
        "    df.drop(columns=[\"_sort_key\"], inplace=True, errors=\"ignore\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "Ms_uC4JlBqLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8D — Mark titles by exact spans and set SentenceRef\n",
        "# What this does:\n",
        "# • Uses NarrativeTagsJSON to mark exact title tokens as TITLE=True.\n",
        "# • Renumbers sentences so:\n",
        "#     if a title exists, it stays at 0 and non-title that were 0 become 1\n",
        "#     if no title exists, shift all sentence ids up by 1 so s000 is unused\n",
        "# • Builds SentenceRef = ID_sNNN\n",
        "# Inputs:  df_map with CorrSentenceID, df_texts_with_tags with tags JSON\n",
        "# Output:  updated df_map\n",
        "# ===============================\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def _parse_json_list(s):\n",
        "    try:\n",
        "        v = json.loads(s) if isinstance(s, str) else (s or [])\n",
        "        return v if isinstance(v, list) else []\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def mark_title_tokens(df_map: pd.DataFrame, df_texts_with_tags: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df_map.copy()\n",
        "\n",
        "    if \"Sentence Boundaries\" not in df.columns:\n",
        "        df[\"Sentence Boundaries\"] = \"\"\n",
        "    if \"TITLE\" not in df.columns:\n",
        "        df[\"TITLE\"] = False\n",
        "\n",
        "    # Collect title spans by ID\n",
        "    title_spans = {}\n",
        "    for _id, corr_text, tags_s in zip(df_texts_with_tags[\"ID\"].astype(str),\n",
        "                                      df_texts_with_tags[\"Corrected text (8)\"].astype(str),\n",
        "                                      df_texts_with_tags[\"NarrativeTagsJSON\"].astype(str)):\n",
        "        tags = _parse_json_list(tags_s)\n",
        "        spans = [(t.get(\"start\", -1), t.get(\"end\", -1))\n",
        "                 for t in tags if isinstance(t, dict) and t.get(\"type\") == \"title\"\n",
        "                 and isinstance(t.get(\"start\"), int) and isinstance(t.get(\"end\"), int)]\n",
        "        if spans:\n",
        "            # Only consider titles near the beginning\n",
        "            spans = [sp for sp in spans if 0 <= sp[0] < max(60, len(corr_text)//3)]\n",
        "        title_spans[str(_id)] = spans\n",
        "\n",
        "    # Mark tokens that are fully inside any title span\n",
        "    def mark_group(g):\n",
        "        gid = str(g[\"ID\"].iloc[0])\n",
        "        spans = title_spans.get(gid, [])\n",
        "        if spans:\n",
        "            for (s0, s1) in spans:\n",
        "                idx = g.index[(g[\"corr_start\"] >= s0) & (g[\"corr_end\"] <= s1)]\n",
        "                if len(idx):\n",
        "                    df.loc[idx, \"TITLE\"] = True\n",
        "                    df.loc[idx, \"Sentence Boundaries\"] = \"Title\"\n",
        "        return g\n",
        "\n",
        "    df.groupby(\"ID\", group_keys=False).apply(mark_group, include_groups=False)\n",
        "\n",
        "    # Renumber sentence ids based on title presence\n",
        "    def bump_group(g):\n",
        "        has_title = bool(g[\"TITLE\"].any())\n",
        "        sids = g[\"CorrSentenceID\"].astype(\"Int64\").copy()\n",
        "        if has_title:\n",
        "            # keep titles at 0, bump other 0 to 1\n",
        "            bump_mask = (~g[\"TITLE\"]) & sids.notna()\n",
        "            sids.loc[bump_mask] = sids.loc[bump_mask] + 1\n",
        "        else:\n",
        "            # no title: all +1 so s000 is unused\n",
        "            mask = sids.notna()\n",
        "            sids.loc[mask] = sids.loc[mask] + 1\n",
        "        g[\"CorrSentenceID\"] = sids\n",
        "        return g\n",
        "\n",
        "    df = df.groupby(\"ID\", group_keys=False).apply(bump_group, include_groups=False).reset_index(drop=True)\n",
        "\n",
        "    # Build SentenceRef = ID_sNNN\n",
        "    def _sid3(x):\n",
        "        try: return f\"{int(x):03d}\"\n",
        "        except: return \"000\"\n",
        "    df[\"SentenceRef\"] = df[\"ID\"].astype(str) + \"_s\" + df[\"CorrSentenceID\"].map(_sid3)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "UY_POvT1BoSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8E — Add explicit boundary flags and checks\n",
        "# What this does:\n",
        "# • Marks the first content token in each sentence as \"Sentence Beginning\".\n",
        "# • Marks the last terminal token as \"Sentence Ending\".\n",
        "# • Adds \"BoundaryCheck\" labels (Correct/Incorrect/Unknown).\n",
        "# Inputs:  df_map from 8D\n",
        "# Output:  updated df_map\n",
        "# ===============================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "TERMINALS_HARD = {\".\",\"!\",\"?\",\"…\",\"...\",\"?!\",\"!?\"}\n",
        "OPENING_PUNCT  = {'\"', \"“\", \"‘\", \"«\", \"(\", \"[\", \"{\"}\n",
        "\n",
        "def _first_alpha_case(s: str):\n",
        "    m = re.search(r\"[A-Za-z]\", s or \"\")\n",
        "    if not m:\n",
        "        return None\n",
        "    return s[m.start()].isupper()\n",
        "\n",
        "def _is_wordish(tok: str) -> bool:\n",
        "    return bool(tok) and bool(re.search(r\"\\w\", str(tok)))\n",
        "\n",
        "def add_sentence_boundary_flags(df_map: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df_map.copy()\n",
        "    for col in (\"Sentence Boundaries\", \"BoundaryCheck\"):\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"\"\n",
        "\n",
        "    if \"corr_index\" not in df.columns:\n",
        "        df[\"corr_index\"] = np.nan\n",
        "\n",
        "    # Stable sort within sentence\n",
        "    df[\"_rowpos\"] = np.arange(len(df))\n",
        "    df[\"_sort_corr\"] = pd.to_numeric(df[\"corr_index\"], errors=\"coerce\").fillna(1e12) + (df[\"_rowpos\"]*1e-9)\n",
        "    df = df.sort_values([\"ID\",\"CorrSentenceID\",\"_sort_corr\"], kind=\"mergesort\")\n",
        "\n",
        "    def _first_content_row(g: pd.DataFrame):\n",
        "        ops = g[\"op\"] if \"op\" in g.columns else pd.Series([\"equal\"]*len(g), index=g.index)\n",
        "        # Prefer first non-insert word (skip opening quotes/brackets)\n",
        "        for idx in g.index:\n",
        "            tok = str(g.at[idx, \"corr_token\"])\n",
        "            if tok in OPENING_PUNCT:\n",
        "                continue\n",
        "            if not _is_wordish(tok):\n",
        "                continue\n",
        "            if ops.at[idx] == \"insert\":\n",
        "                continue\n",
        "            return idx\n",
        "        # Fallback: first wordish token\n",
        "        for idx in g.index:\n",
        "            tok = str(g.at[idx, \"corr_token\"])\n",
        "            if tok in OPENING_PUNCT:\n",
        "                continue\n",
        "            if _is_wordish(tok):\n",
        "                return idx\n",
        "        return None\n",
        "\n",
        "    def _last_terminal_row(g: pd.DataFrame):\n",
        "        toks = g[\"corr_token\"].astype(str).tolist()\n",
        "        for pos in range(len(toks)-1, -1, -1):\n",
        "            if toks[pos] in TERMINALS_HARD:\n",
        "                return g.index[pos]\n",
        "        return None\n",
        "\n",
        "    for (id_, sid), g in df.groupby([\"ID\",\"CorrSentenceID\"], sort=False):\n",
        "        # Title sentences already handled; keep label and skip checks\n",
        "        if \"TITLE\" in g.columns and g[\"TITLE\"].any():\n",
        "            df.loc[g.index, \"Sentence Boundaries\"] = \"Title\"\n",
        "            continue\n",
        "\n",
        "        g = g.sort_values(\"_sort_corr\", kind=\"mergesort\")\n",
        "        b = _first_content_row(g)\n",
        "        e = _last_terminal_row(g)\n",
        "\n",
        "        if b is not None:\n",
        "            prev = df.at[b, \"Sentence Boundaries\"]\n",
        "            if prev.strip() != \"Title\":\n",
        "                df.at[b, \"Sentence Boundaries\"] = prev + (\" | \" if prev else \"\") + \"Sentence Beginning\"\n",
        "                raw_tok = str(df.at[b, \"raw_token\"] or \"\") if \"raw_token\" in df.columns else \"\"\n",
        "                corr_tok = str(df.at[b, \"corr_token\"] or \"\")\n",
        "                ra = _first_alpha_case(raw_tok)\n",
        "                ca = _first_alpha_case(corr_tok)\n",
        "                tag = \"Unknown Beginning\" if (ra is None or ca is None) else (\"Correct Beginning\" if (ra == ca) else \"Incorrect Beginning\")\n",
        "                prev = df.at[b, \"BoundaryCheck\"]\n",
        "                df.at[b, \"BoundaryCheck\"] = prev + (\" | \" if prev else \"\") + tag\n",
        "\n",
        "        if e is not None:\n",
        "            prev = df.at[e, \"Sentence Boundaries\"]\n",
        "            if prev.strip() != \"Title\":\n",
        "                df.at[e, \"Sentence Boundaries\"] = prev + (\" | \" if prev else \"\") + \"Sentence Ending\"\n",
        "                ce_tok = str(df.at[e, \"corr_token\"] or \"\")\n",
        "                tag = \"Correct Ending\" if (ce_tok in TERMINALS_HARD) else \"Incorrect Ending\"\n",
        "                prev = df.at[e, \"BoundaryCheck\"]\n",
        "                df.at[e, \"BoundaryCheck\"] = prev + (\" | \" if prev else \"\") + tag\n",
        "\n",
        "    # Ensure SentenceRef exists/updated\n",
        "    def _sid3(x):\n",
        "        try: return f\"{int(x):03d}\"\n",
        "        except: return \"000\"\n",
        "    df[\"SentenceRef\"] = df[\"ID\"].astype(str) + \"_s\" + df[\"CorrSentenceID\"].map(_sid3)\n",
        "\n",
        "    df.drop(columns=[\"_rowpos\",\"_sort_corr\"], inplace=True, errors=\"ignore\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "GPQ-h2DhCvEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8Z — Step 8 orchestrator\n",
        "# What this does:\n",
        "# • Runs the full Step 8 pipeline in order:\n",
        "#     correction + tags  -> mapping  -> smart alignment repair\n",
        "#     -> sentence IDs -> title marking -> boundary flags\n",
        "# Inputs:  df_preprocessed with [\"ID\",\"Raw text\"]\n",
        "# Outputs: df_texts (per row, corrected text + tags), df_map (long alignment table)\n",
        "# ===============================\n",
        "\n",
        "def run_step8(df_preprocessed: pd.DataFrame,\n",
        "              raw_col=\"Raw text\",\n",
        "              id_col=\"ID\",\n",
        "              client=None,\n",
        "              model=\"gpt-4o\",\n",
        "              use_mock=False):\n",
        "    # 8A: correction + tags\n",
        "    df_corr = run_correct_only(\n",
        "        df_preprocessed,\n",
        "        text_col=raw_col,\n",
        "        id_col=id_col,\n",
        "        client=None if use_mock else client,\n",
        "        model=model,\n",
        "        use_mock=use_mock,\n",
        "        out_col=\"Corrected text (8)\"\n",
        "    )\n",
        "\n",
        "    # Hardening against mojibake, just in case\n",
        "    df_corr[\"Corrected text (8)\"] = df_corr[\"Corrected text (8)\"].map(normalize_mojibake)\n",
        "\n",
        "    # 8B: token map\n",
        "    df_map, df_texts = run_mapping_only(\n",
        "        df_corr, id_col=id_col, raw_col=raw_col, corr_col=\"Corrected text (8)\"\n",
        "    )\n",
        "\n",
        "    # 8R: alignment repair to fold split inserts into clean replacements\n",
        "    df_map = smart_repair_alignment(df_map, window=6, sim_word=0.60, sim_join=0.72)\n",
        "\n",
        "    # 8C: sentence IDs\n",
        "    df_map = assign_corr_sentence_ids(df_map)\n",
        "\n",
        "    # 8D: title tokens and renumbering\n",
        "    df_texts[\"ID\"] = df_texts[\"ID\"].astype(str)\n",
        "    df_map = mark_title_tokens(df_map, df_texts_with_tags=df_texts)\n",
        "\n",
        "    # 8E: boundary flags\n",
        "    df_map = add_sentence_boundary_flags(df_map)\n",
        "\n",
        "    return df_texts, df_map\n"
      ],
      "metadata": {
        "id": "mGETqMYKBjhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 9 — Build sentence table from token map\n",
        "# What this does:\n",
        "# • Aggregates tokens into sentences (excluding title tokens).\n",
        "# • Creates corrected and raw sentence strings.\n",
        "# • Counts edits per sentence and marks begin/end checks.\n",
        "# • Projects dialogue, temporal, and closure flags onto sentences.\n",
        "# Inputs:  df_map (from Step 8), df_texts (from Step 8)\n",
        "# Output:  sent_df (one row per sentence with stats and flags)\n",
        "# ===============================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "def _detok(tokens):\n",
        "    NO_SPACE_BEFORE = set(list(\".,;:!?)]}\\\"'»”’…\"))\n",
        "    NO_SPACE_AFTER  = set(list(\"([{\\\"'«“‘\"))\n",
        "    out = []\n",
        "    for t in tokens:\n",
        "        if t is None or (isinstance(t, float) and np.isnan(t)):\n",
        "            continue\n",
        "        t = str(t)\n",
        "        if not out:\n",
        "            out.append(t); continue\n",
        "        prev = out[-1]\n",
        "        if t in NO_SPACE_BEFORE or re.fullmatch(r\"[.]{3}\", t):\n",
        "            out[-1] = prev + t\n",
        "        elif prev in NO_SPACE_AFTER:\n",
        "            out[-1] = prev + t\n",
        "        else:\n",
        "            out.append(\" \" + t)\n",
        "    s = \"\".join(out)\n",
        "    s = re.sub(r\"\\.\\s*\\.\\s*\\.\", \"...\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def _parse_json_list(s):\n",
        "    try:\n",
        "        v = json.loads(s) if isinstance(s, str) else (s or [])\n",
        "        return v if isinstance(v, list) else []\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def _overlap(a0, a1, b0, b1):\n",
        "    return max(0, min(a1, b1) - max(a0, b0)) > 0\n",
        "\n",
        "def run_step9(df_map: pd.DataFrame, df_texts_with_tags: pd.DataFrame) -> pd.DataFrame:\n",
        "    need = {\"ID\",\"CorrSentenceID\",\"corr_token\",\"Sentence Boundaries\",\"BoundaryCheck\",\"SentenceRef\",\"TITLE\",\"corr_start\",\"corr_end\"}\n",
        "    miss = need - set(df_map.columns)\n",
        "    if miss:\n",
        "        raise KeyError(f\"df_map missing columns needed for Step 9: {miss}\")\n",
        "\n",
        "    wm = df_map.sort_values([\"ID\",\"CorrSentenceID\",\"corr_index\"], kind=\"mergesort\").copy()\n",
        "\n",
        "    # Exclude titles from aggregation\n",
        "    core = wm[~wm[\"TITLE\"].astype(bool)].copy()\n",
        "\n",
        "    # sentence spans in corrected text\n",
        "    sent_spans = (\n",
        "        core.groupby([\"ID\",\"CorrSentenceID\"], as_index=False, sort=False)\n",
        "            .agg(CorrStartMin=(\"corr_start\",\"min\"),\n",
        "                 CorrEndMax=(\"corr_end\",\"max\"))\n",
        "    )\n",
        "\n",
        "    # Summarise each sentence\n",
        "    def _summarize_sentence(g: pd.DataFrame) -> pd.Series:\n",
        "        corr_tokens = g[\"corr_token\"].tolist()\n",
        "        raw_tokens  = [x for x in g[\"raw_token\"].tolist() if not pd.isna(x)] if \"raw_token\" in g.columns else []\n",
        "        corr_text   = _detok(corr_tokens)\n",
        "        raw_text    = _detok(raw_tokens) if raw_tokens else \"\"\n",
        "\n",
        "        b_rows = g[g[\"Sentence Boundaries\"].str.contains(\"Sentence Beginning\", na=False)]\n",
        "        e_rows = g[g[\"Sentence Boundaries\"].str.contains(\"Sentence Ending\",   na=False)]\n",
        "\n",
        "        begin_ok = np.nan\n",
        "        end_ok   = np.nan\n",
        "        if not b_rows.empty:\n",
        "            chk = \" | \".join(b_rows[\"BoundaryCheck\"].dropna().astype(str))\n",
        "            begin_ok = 1 if \"Correct Beginning\" in chk else (0 if \"Incorrect Beginning\" in chk else np.nan)\n",
        "        if not e_rows.empty:\n",
        "            chk = \" | \".join(e_rows[\"BoundaryCheck\"].dropna().astype(str))\n",
        "            end_ok = 1 if \"Correct Ending\" in chk else (0 if \"Incorrect Ending\" in chk else np.nan)\n",
        "\n",
        "        ops = g[\"op\"] if \"op\" in g.columns else pd.Series([], dtype=object)\n",
        "        return pd.Series({\n",
        "            \"SentenceRef\": g[\"SentenceRef\"].iloc[0],\n",
        "            \"CorrectedSentence\": corr_text,\n",
        "            \"RawSentence\": raw_text,\n",
        "            \"TokensInSentence\": int(len(g)),\n",
        "            \"EditsInSentence\": int((ops != \"equal\").sum()) if not ops.empty else np.nan,\n",
        "            \"EqualsInSentence\": int((ops == \"equal\").sum()) if not ops.empty else np.nan,\n",
        "            \"Insertions\": int((ops == \"insert\").sum()) if not ops.empty else np.nan,\n",
        "            \"Deletions\": int((ops == \"delete\").sum()) if not ops.empty else np.nan,\n",
        "            \"Replacements\": int((ops == \"replace\").sum()) if not ops.empty else np.nan,\n",
        "            \"BeginBoundaryRow\": (b_rows.index[0] if not b_rows.empty else np.nan),\n",
        "            \"EndBoundaryRow\":   (e_rows.index[0] if not e_rows.empty else np.nan),\n",
        "            \"CorrectBeginning\": begin_ok,\n",
        "            \"CorrectEnding\":    end_ok,\n",
        "        })\n",
        "\n",
        "    sent_df = (\n",
        "        core.groupby([\"ID\",\"CorrSentenceID\"], as_index=False, sort=False)\n",
        "            .apply(_summarize_sentence, include_groups=False)\n",
        "            .reset_index(drop=True)\n",
        "            .sort_values([\"ID\",\"SentenceRef\"], kind=\"mergesort\")\n",
        "    )\n",
        "\n",
        "    # Project dialogue, temporal, closure flags\n",
        "    df_texts = df_texts_with_tags[[\"ID\",\"Corrected text (8)\",\"NarrativeTagsJSON\",\"DialogueSpansJSON\"]].copy()\n",
        "    df_texts[\"ID\"] = df_texts[\"ID\"].astype(str)\n",
        "\n",
        "    sent_df = sent_df.merge(sent_spans, on=[\"ID\",\"CorrSentenceID\"], how=\"left\")\n",
        "    sent_df = sent_df.merge(df_texts, on=\"ID\", how=\"left\")\n",
        "\n",
        "    def _flags(row):\n",
        "        s0, s1 = row[\"CorrStartMin\"], row[\"CorrEndMax\"]\n",
        "\n",
        "        # dialogue\n",
        "        has_dialogue = False\n",
        "        dlg = _parse_json_list(row.get(\"DialogueSpansJSON\",\"[]\"))\n",
        "        for d in dlg:\n",
        "            try:\n",
        "                ds, de = int(d.get(\"start\",-1)), int(d.get(\"end\",-1))\n",
        "                if ds >= 0 and de >= 0 and _overlap(s0, s1, ds, de):\n",
        "                    has_dialogue = True\n",
        "                    break\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # temporal and closure\n",
        "        has_temporal = False\n",
        "        has_closure  = False\n",
        "        tags = _parse_json_list(row.get(\"NarrativeTagsJSON\",\"[]\"))\n",
        "        for t in tags:\n",
        "            try:\n",
        "                tt = t.get(\"type\",\"\")\n",
        "                ts, te = int(t.get(\"start\",-1)), int(t.get(\"end\",-1))\n",
        "                if ts >= 0 and te >= 0 and _overlap(s0, s1, ts, te):\n",
        "                    if tt == \"temporal\":\n",
        "                        has_temporal = True\n",
        "                    elif tt == \"closure\":\n",
        "                        has_closure = True\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return pd.Series({\"IsDialogue\": has_dialogue, \"HasTemporal\": has_temporal, \"HasClosure\": has_closure})\n",
        "\n",
        "    sent_df = pd.concat([sent_df, sent_df.apply(_flags, axis=1)], axis=1)\n",
        "\n",
        "    # Clean helper columns\n",
        "    for c in [\"CorrStartMin\",\"CorrEndMax\",\"Corrected text (8)\",\"NarrativeTagsJSON\",\"DialogueSpansJSON\"]:\n",
        "        if c in sent_df.columns:\n",
        "            sent_df.drop(columns=[c], inplace=True)\n",
        "\n",
        "    return sent_df\n"
      ],
      "metadata": {
        "id": "65Jmq0InBgfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 9.5 — Run Step 8 + Step 9, save, and (optionally) download\n",
        "#        (ID-hardened + progress bar)\n",
        "# ===============================================\n",
        "import os, time, zipfile\n",
        "from typing import Dict\n",
        "try:\n",
        "    from tqdm.auto import tqdm\n",
        "    _HAVE_TQDM = True\n",
        "except Exception:\n",
        "    _HAVE_TQDM = False\n",
        "\n",
        "try:\n",
        "    from google.colab import files as _colab_files\n",
        "    _IN_COLAB = True\n",
        "except Exception:\n",
        "    _colab_files = None\n",
        "    _IN_COLAB = False\n",
        "\n",
        "def _ensure_dir(path: str) -> str:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "def _safe_download(path: str):\n",
        "    if _IN_COLAB and _colab_files:\n",
        "        try:\n",
        "            _colab_files.download(path)\n",
        "        except Exception as e:\n",
        "            print(f\"   ↳ Download hint: {e}\")\n",
        "\n",
        "def save_and_download_step8_9(\n",
        "    df_preprocessed,\n",
        "    *,\n",
        "    raw_col: str = \"Raw text\",\n",
        "    id_col: str = \"ID\",\n",
        "    client=None,\n",
        "    model: str = \"gpt-4o\",\n",
        "    use_mock: bool = False,\n",
        "    out_dir: str = \"/content/drive/MyDrive/JM/Outputs\",\n",
        "    prefix: str = \"step\"\n",
        ") -> Dict[str, object]:\n",
        "    if df_preprocessed is None or len(df_preprocessed) == 0:\n",
        "        raise ValueError(\"df_preprocessed is empty or not defined.\")\n",
        "    if raw_col not in df_preprocessed.columns:\n",
        "        raise KeyError(f\"'{raw_col}' not found in df_preprocessed.\")\n",
        "\n",
        "    # Normalize/guarantee ID once for the whole run\n",
        "    df_work, id_source = ensure_canonical_id(df_preprocessed, canon=id_col)\n",
        "\n",
        "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    _ensure_dir(out_dir)\n",
        "\n",
        "    bar = tqdm(total=8, desc=\"Pipeline 8→9\", unit=\"step\") if _HAVE_TQDM else None\n",
        "    def _tick(msg):\n",
        "        if bar:\n",
        "            bar.set_postfix_str(msg[:60]); bar.update(1)\n",
        "\n",
        "    print(f\"▶️  Running Step 8 (correction, mapping, boundaries)...  [ID source: {id_source}]\")\n",
        "    df_texts_8, df_map_8 = run_step8(\n",
        "        df_work, raw_col=raw_col, id_col=id_col,\n",
        "        client=None if use_mock else client, model=model, use_mock=use_mock\n",
        "    )\n",
        "    _tick(\"Step 8 complete\")\n",
        "    print(f\"   ✓ Step 8 complete — rows: {len(df_texts_8):,}, map rows: {len(df_map_8):,}\")\n",
        "\n",
        "    print(\"▶️  Running Step 9 (sentence table)...\")\n",
        "    sent_df = run_step9(df_map_8, df_texts_with_tags=df_texts_8)\n",
        "    _tick(\"Step 9 complete\")\n",
        "    print(f\"   ✓ Step 9 complete — sentences: {len(sent_df):,}\")\n",
        "\n",
        "    base = f\"{prefix}_8_9_{ts}\"\n",
        "    p_texts = os.path.join(out_dir, f\"{base}_texts.csv\")\n",
        "    p_map   = os.path.join(out_dir, f\"{base}_wordmap_checked.csv\")\n",
        "    p_sent  = os.path.join(out_dir, f\"{base}_sentence_mapping_with_boundaries.csv\")\n",
        "    p_zip   = os.path.join(out_dir, f\"{base}.zip\")\n",
        "\n",
        "    print(\"💾 Saving CSVs...\")\n",
        "    df_texts_8.to_csv(p_texts, index=False, encoding=\"utf-8\"); _tick(\"Saved texts CSV\")\n",
        "    df_map_8.to_csv(p_map,   index=False, encoding=\"utf-8\");   _tick(\"Saved wordmap CSV\")\n",
        "    sent_df.to_csv(p_sent,   index=False, encoding=\"utf-8\");   _tick(\"Saved sentences CSV\")\n",
        "    print(\"   •\", p_texts); print(\"   •\", p_map); print(\"   •\", p_sent)\n",
        "\n",
        "    print(\"🗜️  Bundling ZIP...\")\n",
        "    with zipfile.ZipFile(p_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        zf.write(p_texts, arcname=os.path.basename(p_texts))\n",
        "        zf.write(p_map,   arcname=os.path.basename(p_map))\n",
        "        zf.write(p_sent,  arcname=os.path.basename(p_sent))\n",
        "    _tick(\"ZIP complete\")\n",
        "    print(\"   •\", p_zip)\n",
        "\n",
        "    if _IN_COLAB:\n",
        "        print(\"⬇️  Initiating downloads (Colab)...\")\n",
        "        for p in (p_texts, p_map, p_sent, p_zip):\n",
        "            _safe_download(p)\n",
        "        _tick(\"Downloads triggered\")\n",
        "    else:\n",
        "        print(\"ℹ️  Not running in Colab — files saved to disk only.\")\n",
        "        _tick(\"Skipped downloads\")\n",
        "\n",
        "    try:\n",
        "        print(\"\\n— Per document (first 10) —\")\n",
        "        preview = (\n",
        "            df_map_8.groupby(\"ID\")[\"op\"]\n",
        "                    .apply(lambda s: (s != \"equal\").sum())\n",
        "                    .rename(\"Edits\").reset_index()\n",
        "                    .sort_values(\"ID\").head(10)\n",
        "        )\n",
        "        print(preview.to_string(index=False))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        print(\"\\n— First 10 sentences with boundary checks —\")\n",
        "        cols = [\"SentenceRef\",\"CorrectedSentence\",\"CorrectBeginning\",\"CorrectEnding\",\n",
        "                \"EditsInSentence\",\"IsDialogue\",\"HasTemporal\",\"HasClosure\"]\n",
        "        print(sent_df[cols].head(10).to_string(index=False))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    if bar:\n",
        "        bar.set_postfix_str(\"Done\"); bar.update(1); bar.close()\n",
        "\n",
        "    return dict(\n",
        "        step8_texts_path=p_texts,\n",
        "        step8_map_path=p_map,\n",
        "        step9_sentences_path=p_sent,\n",
        "        zip_path=p_zip,\n",
        "        df_texts_8=df_texts_8,\n",
        "        df_map_8=df_map_8,\n",
        "        sent_df=sent_df\n",
        "    )\n"
      ],
      "metadata": {
        "id": "LCb4F34knnsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Sanity + Retrieve Outputs (run this) --\n",
        "import os, glob, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/JM/Outputs\"\n",
        "print(\"OUT_DIR exists:\", os.path.isdir(OUT_DIR), \"→\", OUT_DIR)\n",
        "\n",
        "# Find the newest run\n",
        "candidates = sorted(glob.glob(os.path.join(OUT_DIR, \"step_8_9_*_texts.csv\")))\n",
        "print(\"Found runs:\", len(candidates))\n",
        "if candidates:\n",
        "    latest_texts = candidates[-1]\n",
        "    stem = latest_texts.replace(\"_texts.csv\",\"\")\n",
        "    latest_map  = stem + \"_wordmap_checked.csv\"\n",
        "    latest_sent = stem + \"_sentence_mapping_with_boundaries.csv\"\n",
        "    latest_zip  = stem + \".zip\"\n",
        "\n",
        "    def _size(p):\n",
        "        try: return f\"{os.path.getsize(p)/1024:.1f} KB\"\n",
        "        except: return \"missing\"\n",
        "\n",
        "    print(\"\\nLatest run:\")\n",
        "    print(\"  Texts CSV    :\", latest_texts, \"(\", _size(latest_texts), \")\")\n",
        "    print(\"  Word-map CSV :\", latest_map,   \"(\", _size(latest_map),   \")\")\n",
        "    print(\"  Sentences CSV:\", latest_sent,  \"(\", _size(latest_sent),  \")\")\n",
        "    print(\"  ZIP bundle   :\", latest_zip,   \"(\", _size(latest_zip),   \")\")\n",
        "\n",
        "    # Peek contents so you can see it's real\n",
        "    try:\n",
        "        df_texts = pd.read_csv(latest_texts, nrows=5)\n",
        "        print(\"\\nTexts head:\")\n",
        "        display(df_texts)\n",
        "    except Exception as e:\n",
        "        print(\"Couldn't preview texts:\", e)\n",
        "\n",
        "    try:\n",
        "        df_sent = pd.read_csv(latest_sent, nrows=5)\n",
        "        print(\"\\nSentences head:\")\n",
        "        display(df_sent[[\"SentenceRef\",\"CorrectedSentence\"]])\n",
        "    except Exception as e:\n",
        "        print(\"Couldn't preview sentences:\", e)\n",
        "\n",
        "    # Re-trigger downloads (one by one; pop-ups may be blocked)\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\nTriggering a single download: ZIP (easiest).\")\n",
        "        files.download(latest_zip)\n",
        "        # If you want all of them uncomment below:\n",
        "        # files.download(latest_texts)\n",
        "        # files.download(latest_map)\n",
        "        # files.download(latest_sent)\n",
        "    except Exception as e:\n",
        "        print(\"Download hint:\", e, \"— if pop-ups are blocked, allow them and run again.\")\n",
        "else:\n",
        "    print(\"No outputs found in OUT_DIR. Re-run the Patch+Final cell, then rerun this.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bOtdQ0awK2H",
        "outputId": "3fec6476-c731-4309-8b68-a806295b8c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUT_DIR exists: True → /content/drive/MyDrive/JM/Outputs\n",
            "Found runs: 0\n",
            "No outputs found in OUT_DIR. Re-run the Patch+Final cell, then rerun this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Hotfix: ID Guard (drop this once, above your launcher) ===\n",
        "import pandas as pd\n",
        "\n",
        "def _guarantee_id(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Always return a copy with a solid 'ID' column (string), pulled from best available.\"\"\"\n",
        "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        raise ValueError(\"ID Guard: input df missing or empty\")\n",
        "    prefer = [\"ID\", \"Research ID\", \"ResearchID\", \"IdeaID\", \"RowID\"]\n",
        "    out = df.copy()\n",
        "    src = next((c for c in prefer if c in out.columns), None)\n",
        "    if src is None:\n",
        "        out[\"ID\"] = out.index.astype(str)\n",
        "    else:\n",
        "        out[\"ID\"] = out[src].astype(str)\n",
        "    # tidy numeric-looking ids like '123.0' → '123'\n",
        "    out[\"ID\"] = (out[\"ID\"].astype(str).str.strip()\n",
        "                 .str.replace(r\"\\.0$\", \"\", regex=True))\n",
        "    return out\n",
        "\n",
        "# --- Wrap run_correct_only safely (no recursion) ---\n",
        "try:\n",
        "    _orig_run_correct_only = run_correct_only\n",
        "except NameError:\n",
        "    _orig_run_correct_only = None\n",
        "\n",
        "def run_correct_only(\n",
        "    df_in: pd.DataFrame,\n",
        "    text_col=\"Raw text\",\n",
        "    id_col=\"ID\",\n",
        "    client=None,\n",
        "    model=\"gpt-4o\",\n",
        "    use_mock=False,\n",
        "    out_col=\"Corrected text (8)\"\n",
        ") -> pd.DataFrame:\n",
        "    if text_col not in df_in.columns:\n",
        "        raise KeyError(f\"Missing required column: '{text_col}'\")\n",
        "    bas\n"
      ],
      "metadata": {
        "id": "6mZB3tIAzNgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fix & harden run_correct_only (kills the 'bas' NameError) ---\n",
        "\n",
        "import pandas as pd, json, re\n",
        "\n",
        "def _guarantee_id(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    prefer = [\"ID\", \"Research ID\", \"ResearchID\", \"IdeaID\", \"RowID\"]\n",
        "    out = df.copy()\n",
        "    src = next((c for c in prefer if c in out.columns), None)\n",
        "    if src is None:\n",
        "        out[\"ID\"] = out.index.astype(str)\n",
        "    else:\n",
        "        out[\"ID\"] = out[src].astype(str)\n",
        "    out[\"ID\"] = out[\"ID\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "    return out\n",
        "\n",
        "# Keep any original for delegation (avoids recursion)\n",
        "try:\n",
        "    _orig_run_correct_only\n",
        "except NameError:\n",
        "    _orig_run_correct_only = None\n",
        "\n",
        "def run_correct_only(\n",
        "    df_in: pd.DataFrame,\n",
        "    text_col=\"Raw text\",\n",
        "    id_col=\"ID\",\n",
        "    client=None,\n",
        "    model=\"gpt-4o\",\n",
        "    use_mock=False,\n",
        "    out_col=\"Corrected text (8)\"\n",
        ") -> pd.DataFrame:\n",
        "    if text_col not in df_in.columns:\n",
        "        raise KeyError(f\"Missing required column: '{text_col}'\")\n",
        "\n",
        "    base = _guarantee_id(df_in)  # ← this was 'bas' before\n",
        "\n",
        "    # If there’s an earlier implementation, delegate safely\n",
        "    if _orig_run_correct_only and _orig_run_correct_only is not run_correct_only:\n",
        "        tmp = base.copy()\n",
        "        tmp[id_col] = tmp[\"ID\"]\n",
        "        out = _orig_run_correct_only(\n",
        "            tmp, text_col=text_col, id_col=id_col,\n",
        "            client=client, model=model, use_mock=use_mock, out_col=out_col\n",
        "        )\n",
        "        return _guarantee_id(out)\n",
        "\n",
        "    # Otherwise, do the full correction here using your correct_with_tags()\n",
        "    corrected, tags_json, dlg_json, sources = [], [], [], []\n",
        "    for raw in base[text_col].astype(str).tolist():\n",
        "        c, tags, spans, src = correct_with_tags(\n",
        "            raw, client=client, model=model, use_mock=use_mock\n",
        "        )\n",
        "        corrected.append(c)\n",
        "        tags_json.append(json.dumps(tags, ensure_ascii=False))\n",
        "        dlg_json.append(json.dumps(spans, ensure_ascii=False))\n",
        "        sources.append(src)\n",
        "\n",
        "    out = base.copy()\n",
        "    out[out_col] = corrected\n",
        "    out[\"NarrativeTagsJSON\"] = tags_json\n",
        "    out[\"DialogueSpansJSON\"]  = dlg_json\n",
        "    out[\"CorrectedBy\"]        = sources\n",
        "    return _guarantee_id(out)\n",
        "\n",
        "print(\"✅ Patched run_correct_only: typo fixed, ID guaranteed, real/Mock path intact.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpYG4DTxzfP3",
        "outputId": "65cd3fe2-9ab2-40a0-f6da-e34bee78b28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched run_correct_only: typo fixed, ID guaranteed, real/Mock path intact.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === REAL RUN LAUNCHER (gpt-4o) ===\n",
        "# Requirements:\n",
        "#  - You already ran your function/defs cells (so save_and_download_step8_9 exists)\n",
        "#  - You already mounted Drive and loaded df_preprocessed with a \"Raw text\" column\n",
        "\n",
        "USE_OPENAI = True\n",
        "MODEL = \"gpt-4o\"\n",
        "OUT_DIR = \"/content/drive/MyDrive/JM/Outputs\"\n",
        "\n",
        "import os, time\n",
        "from getpass import getpass\n",
        "\n",
        "# 1) Secure key entry (hidden) — NEVER paste keys into cells.\n",
        "os.environ.pop(\"OPENAI_API_KEY\", None)\n",
        "print(\"Enter your OpenAI API key (input hidden):\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"API key: \").strip()\n",
        "\n",
        "# 2) Client probe (verifies the key works)\n",
        "from openai import OpenAI\n",
        "try:\n",
        "    OPENAI_CLIENT = OpenAI()\n",
        "    _ = OPENAI_CLIENT.models.list().data[:1]\n",
        "    print(\"✅ OpenAI client ready.\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"OpenAI init failed: {type(e).__name__} - {e}\")\n",
        "\n",
        "# 3) Sanity checks for data + functions\n",
        "import pandas as pd, os\n",
        "\n",
        "if 'df_preprocessed' not in globals() or not isinstance(df_preprocessed, pd.DataFrame):\n",
        "    raise RuntimeError(\"df_preprocessed is not defined. Run your Step 2 Load/Preprocess cell first.\")\n",
        "if \"Raw text\" not in df_preprocessed.columns:\n",
        "    raise KeyError(\"Missing 'Raw text' column in df_preprocessed.\")\n",
        "if 'save_and_download_step8_9' not in globals():\n",
        "    raise RuntimeError(\"save_and_download_step8_9 is not defined. Run the big definitions cell first.\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# 4) Fire the pipeline (REAL model, no mock)\n",
        "print(\"▶️  Running Step 8→9 with REAL model (this does paid API calls).\")\n",
        "results = save_and_download_step8_9(\n",
        "    df_preprocessed,\n",
        "    raw_col=\"Raw text\",\n",
        "    id_col=\"ID\",            # will prefer 'Research ID' if present (via ensure_canonical_id)\n",
        "    client=OPENAI_CLIENT,\n",
        "    model=MODEL,\n",
        "    use_mock=False,         # <-- real calls\n",
        "    out_dir=OUT_DIR,\n",
        "    prefix=\"step\"\n",
        ")\n",
        "\n",
        "# 5) Summary of output paths\n",
        "print(\"\\n🎯 Done. Key output files:\")\n",
        "print(\"  • Texts CSV:     \", results.get(\"step8_texts_path\"))\n",
        "print(\"  • Word-map CSV:  \", results.get(\"step8_map_path\"))\n",
        "print(\"  • Sentences CSV: \", results.get(\"step9_sentences_path\"))\n",
        "print(\"  • ZIP bundle:    \", results.get(\"zip_path\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700,
          "referenced_widgets": [
            "53e5abf875a54b06a503c1789524b71f",
            "a7b3f46791b447f59967507ca2389084",
            "46db896af6ed4974b6332a081aae7ba9",
            "8400c8b1255d4a75b2607c760af1fa56",
            "f1e244bc35bf4ff79a5e3a171b0aa88a",
            "d79136f2e5364869b43db8b3910cdcee",
            "0dede349de3148da910f205e76443fc2",
            "6e4103dfe48f405b953397565ca9b9c1",
            "d945cb91eefb487399b17d2ca3bce621",
            "fcbd37f180d6467583489995b3b4c0e6",
            "acc2c61080fd43a3b01e2da10e62fd2e"
          ]
        },
        "id": "Rc77Iem4xSLu",
        "outputId": "97480974-bc95-4815-b705-f52088884611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key (input hidden):\n",
            "API key: ··········\n",
            "✅ OpenAI client ready.\n",
            "▶️  Running Step 8→9 with REAL model (this does paid API calls).\n",
            "ℹ️  Using 'Research ID' as canonical 'ID'.\n",
            "🔎 ID check → ['BBCMHJPT', 'BBKBYNDW', 'BBRWTLYV', 'BCDVWQDF', 'BCXSFTWC']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pipeline 8→9:   0%|          | 0/8 [00:00<?, ?step/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53e5abf875a54b06a503c1789524b71f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️  Running Step 8 (correction, mapping, boundaries)...  [ID source: Research ID]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'ID'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ID'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-128964419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# 4) Fire the pipeline (REAL model, no mock)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"▶️  Running Step 8→9 with REAL model (this does paid API calls).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m results = save_and_download_step8_9(\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mdf_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mraw_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Raw text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3937392929.py\u001b[0m in \u001b[0;36msave_and_download_step8_9\u001b[0;34m(df_preprocessed, raw_col, id_col, client, model, use_mock, out_dir, prefix)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"▶️  Running Step 8 (correction, mapping, boundaries)...  [ID source: {id_source}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     df_texts_8, df_map_8 = run_step8(\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mdf_work\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_mock\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_mock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1458734688.py\u001b[0m in \u001b[0;36mrun_step8\u001b[0;34m(df_preprocessed, raw_col, id_col, client, model, use_mock)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# 8D: title tokens and renumbering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdf_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mdf_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmark_title_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_texts_with_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# 8E: boundary flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-117394194.py\u001b[0m in \u001b[0;36mmark_title_tokens\u001b[0;34m(df_map, df_texts_with_tags)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmark_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Renumber sentence ids based on title presence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_with_exclusions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1883\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \"\"\"\n\u001b[0;32m-> 1885\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_groupwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnot_indexed_same\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m             \u001b[0mnot_indexed_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-117394194.py\u001b[0m in \u001b[0;36mmark_group\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Mark tokens that are fully inside any title span\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmark_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mgid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mspans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle_spans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ID'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "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\n"
      ],
      "metadata": {
        "id": "dFCyxgm7zTh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fZks_smPPVig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Below is archived - Please ignore\n"
      ],
      "metadata": {
        "id": "oKmA8CKXNtEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the code that will introduce the functions"
      ],
      "metadata": {
        "id": "R8RCwD9aVxM7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnktVEBRuJsbkSS2p8CGDy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c614125d7df3424599ae8c6f7917e3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b9a648cd6e4d72a4acea342f727efe",
            "placeholder": "​",
            "style": "IPY_MODEL_e8ab5a48f965475cad28034238b67648",
            "value": "<h4>Download a CSV Template</h4>"
          }
        },
        "f1b9a648cd6e4d72a4acea342f727efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8ab5a48f965475cad28034238b67648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "394935e6562844939073c758bcc6b824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55e0b2ffc5e54c5fa3470f3e6a2b41e4",
            "placeholder": "​",
            "style": "IPY_MODEL_9c5657533e89428d9a4f116d2f3a31e2",
            "value": "Use the first column as <b>ID</b> and the last as <b>Raw text</b>.<br>Everything in between is optional."
          }
        },
        "55e0b2ffc5e54c5fa3470f3e6a2b41e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5657533e89428d9a4f116d2f3a31e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8841570d2e8042d2b9a4ac34165410ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5cfd5ece48d4e678534fcee0e169b10",
              "IPY_MODEL_a15408a9c67e4311a3af2c7f647eeaa0"
            ],
            "layout": "IPY_MODEL_d4b37fb87abf40b7a0ec74df8cd29659"
          }
        },
        "c5cfd5ece48d4e678534fcee0e169b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "⬇️ Download Minimal Template (ID + Raw text)",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_0656922103d943f0a9cf622262bca3d7",
            "style": "IPY_MODEL_8e0e76b92fb04a078ae1f87a4b850e6c",
            "tooltip": ""
          }
        },
        "a15408a9c67e4311a3af2c7f647eeaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "⬇️ Download Extended Template (Full NAPLAN-style)",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9d7712f4b50b49f1adb639bda7935e59",
            "style": "IPY_MODEL_99432b51260848629ec9a29af72eb88e",
            "tooltip": ""
          }
        },
        "d4b37fb87abf40b7a0ec74df8cd29659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0656922103d943f0a9cf622262bca3d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e0e76b92fb04a078ae1f87a4b850e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9d7712f4b50b49f1adb639bda7935e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99432b51260848629ec9a29af72eb88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "de3d763ecee449439e9e2f59e8aba021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cbe64ca836b45cda22d02345dcf0091",
              "IPY_MODEL_91651029021545fd995c893e6d74fb90"
            ],
            "layout": "IPY_MODEL_e00a959c21c54d8593f8b2ca9b7936fa"
          }
        },
        "0cbe64ca836b45cda22d02345dcf0091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "CSV",
              "Excel (.xlsx)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Format:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_084377e1ea52447c9e47212bb32c94a5",
            "style": "IPY_MODEL_ed1b22b478c345038fa4702cd53b9451"
          }
        },
        "91651029021545fd995c893e6d74fb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Download DataFrame now",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a38317f577ee42f9bc15322d524a4f19",
            "style": "IPY_MODEL_573cf0a44f4e44adbc61f011fcd5ede5",
            "tooltip": "Click to download the DataFrame with WordCount and TokenCount"
          }
        },
        "e00a959c21c54d8593f8b2ca9b7936fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "084377e1ea52447c9e47212bb32c94a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "240px"
          }
        },
        "ed1b22b478c345038fa4702cd53b9451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a38317f577ee42f9bc15322d524a4f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "573cf0a44f4e44adbc61f011fcd5ede5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c126e1e7c9f6442aad8974ee2411d2e8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f345f48e25ea4d6abfec3c84f2f116f6",
            "msg_id": "",
            "outputs": []
          }
        },
        "f345f48e25ea4d6abfec3c84f2f116f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642ac1f6f9ac4e55be4d98bc4a59c363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dac6b65232e41e2864f7109878bd7c7",
              "IPY_MODEL_6962d7dbc9824c52b6fa73f62c7afd18",
              "IPY_MODEL_6cdf86d04f334ebfa0b2a25cf077b108",
              "IPY_MODEL_8d692e65004642c8a71732b4ac09fdb5",
              "IPY_MODEL_9c61613cb7494ff29253eb302cb68883"
            ],
            "layout": "IPY_MODEL_d0d5c54cc51a421e9740de1e952fe97c"
          }
        },
        "2dac6b65232e41e2864f7109878bd7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "LOG_FILE:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ebd54a5e2551483c84415e62ab4cb190",
            "placeholder": "​",
            "style": "IPY_MODEL_6003d7e673d143f186eb20118b99c449",
            "value": "text_correction.log"
          }
        },
        "6962d7dbc9824c52b6fa73f62c7afd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7729ca1562024e248e1fda751ba7419a",
              "IPY_MODEL_05cc2de09f45485a8e866fddc4b4cd86"
            ],
            "layout": "IPY_MODEL_c005febb173b4713ba82370fdf852b6b"
          }
        },
        "6cdf86d04f334ebfa0b2a25cf077b108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43a3bd9d92c04658ba5ae4865b1c7fe0",
              "IPY_MODEL_c532338581d2429e90fc6fe55eb8e0db"
            ],
            "layout": "IPY_MODEL_ac36d91201034ba59067477bd436909c"
          }
        },
        "8d692e65004642c8a71732b4ac09fdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc366d499fe44373a5fbffc4fa5d4194",
              "IPY_MODEL_964859d1269148f18025b853593d9ba0",
              "IPY_MODEL_3c4029a0339243aa80b8c877a2f8d4ee"
            ],
            "layout": "IPY_MODEL_7eb5afcd7f6d4e7bb03533bad2a6b7ad"
          }
        },
        "9c61613cb7494ff29253eb302cb68883": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8c038de713b9412d90abeb136a2e57ad",
            "msg_id": "",
            "outputs": []
          }
        },
        "d0d5c54cc51a421e9740de1e952fe97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd54a5e2551483c84415e62ab4cb190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "420px"
          }
        },
        "6003d7e673d143f186eb20118b99c449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7729ca1562024e248e1fda751ba7419a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "DEBUG (most verbose)",
              "INFO (standard)",
              "WARNING (only important)",
              "ERROR (failures only)",
              "CRITICAL"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Console:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_6335828f32744e61a09b7509658b81e0",
            "style": "IPY_MODEL_233086638fc44d07be166499e1575aa0"
          }
        },
        "05cc2de09f45485a8e866fddc4b4cd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "DEBUG (most verbose)",
              "INFO (standard)",
              "WARNING (only important)",
              "ERROR (failures only)",
              "CRITICAL"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "File:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_c174822677b84b6099f4bbcff5673bc6",
            "style": "IPY_MODEL_203a9d7301d941c99ad37428f77f9435"
          }
        },
        "c005febb173b4713ba82370fdf852b6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a3bd9d92c04658ba5ae4865b1c7fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": false,
            "description": "Rotate MB:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_825f68bbcd984df0b53f4d1b32179f49",
            "max": 50,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_6fb24ec72a424f91a9e6646d6ccde3d5",
            "value": 5
          }
        },
        "c532338581d2429e90fc6fe55eb8e0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": false,
            "description": "Backups:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3a5095671e684c2f9372d81d96f0f0b3",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_966cc2aea794474fac115f19d4bb924a",
            "value": 3
          }
        },
        "ac36d91201034ba59067477bd436909c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc366d499fe44373a5fbffc4fa5d4194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Apply logging settings",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4b88c4c8354c475c99feb02bb7cee1f6",
            "style": "IPY_MODEL_06e9045b478542d39f5a88ac466c500f",
            "tooltip": "Configure handlers and run a quick self-test"
          }
        },
        "964859d1269148f18025b853593d9ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Show log tail",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2f0f5543d01c41e195729df06c58095c",
            "style": "IPY_MODEL_1fde0096dc0b474ea6392288835c90c2",
            "tooltip": "Display the last lines of the current log file"
          }
        },
        "3c4029a0339243aa80b8c877a2f8d4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Download log",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ef45aa6a8cb847cea8db908f775edf8d",
            "style": "IPY_MODEL_dbcbeb8b6390453fa24d1624a30ac3f4",
            "tooltip": "Download the current log file"
          }
        },
        "7eb5afcd7f6d4e7bb03533bad2a6b7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6335828f32744e61a09b7509658b81e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "420px"
          }
        },
        "233086638fc44d07be166499e1575aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c174822677b84b6099f4bbcff5673bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "420px"
          }
        },
        "203a9d7301d941c99ad37428f77f9435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "825f68bbcd984df0b53f4d1b32179f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb24ec72a424f91a9e6646d6ccde3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "3a5095671e684c2f9372d81d96f0f0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966cc2aea794474fac115f19d4bb924a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "4b88c4c8354c475c99feb02bb7cee1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e9045b478542d39f5a88ac466c500f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2f0f5543d01c41e195729df06c58095c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fde0096dc0b474ea6392288835c90c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ef45aa6a8cb847cea8db908f775edf8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbcbeb8b6390453fa24d1624a30ac3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8c038de713b9412d90abeb136a2e57ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e5abf875a54b06a503c1789524b71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7b3f46791b447f59967507ca2389084",
              "IPY_MODEL_46db896af6ed4974b6332a081aae7ba9",
              "IPY_MODEL_8400c8b1255d4a75b2607c760af1fa56"
            ],
            "layout": "IPY_MODEL_f1e244bc35bf4ff79a5e3a171b0aa88a"
          }
        },
        "a7b3f46791b447f59967507ca2389084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79136f2e5364869b43db8b3910cdcee",
            "placeholder": "​",
            "style": "IPY_MODEL_0dede349de3148da910f205e76443fc2",
            "value": "Pipeline 8→9:   0%"
          }
        },
        "46db896af6ed4974b6332a081aae7ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e4103dfe48f405b953397565ca9b9c1",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d945cb91eefb487399b17d2ca3bce621",
            "value": 0
          }
        },
        "8400c8b1255d4a75b2607c760af1fa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcbd37f180d6467583489995b3b4c0e6",
            "placeholder": "​",
            "style": "IPY_MODEL_acc2c61080fd43a3b01e2da10e62fd2e",
            "value": " 0/8 [00:00&lt;?, ?step/s]"
          }
        },
        "f1e244bc35bf4ff79a5e3a171b0aa88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79136f2e5364869b43db8b3910cdcee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dede349de3148da910f205e76443fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e4103dfe48f405b953397565ca9b9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d945cb91eefb487399b17d2ca3bce621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcbd37f180d6467583489995b3b4c0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc2c61080fd43a3b01e2da10e62fd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}