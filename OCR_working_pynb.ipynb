{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4Kt1wCeKv/rSuVEiqJRga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elijahManPerson/Flappy-Bird/blob/master/OCR_working_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RAM2GzZyT61",
        "outputId": "b1cb9cee-98ce-4278-bf12-e343782effca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "gradio 5.49.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 1) Install system packages and fonts\n",
        "!apt-get update -qq\n",
        "!apt-get install -y fonts-dejavu-core -qq\n",
        "!pip -q install --upgrade openai pymupdf reportlab pandas openpyxl tqdm pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Python implementation\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import re\n",
        "import base64\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "from PIL import Image\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.utils import ImageReader\n",
        "from reportlab.pdfbase.pdfmetrics import stringWidth\n",
        "from reportlab.pdfbase import pdfmetrics\n",
        "from reportlab.pdfbase.ttfonts import TTFont\n",
        "\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "OLRlPc0ByXnZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdgO1mRyZmm",
        "outputId": "d7865648-469f-41aa-ded3-d3d8e4739d54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Configuration - change these paths if you want\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/handwriting_pdfs\"   # where your PDFs live\n",
        "OUTPUT_DIR   = \"/content/drive/MyDrive/handwriting_outputs\"  # where outputs will be written\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "pdZ6XRVAybO8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Secure API key input\n",
        "from getpass import getpass\n",
        "OPENAI_KEY = getpass(\"Paste your OpenAI API key (starts with sk-): \").strip()\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
        "client = OpenAI(api_key=OPENAI_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcyp7MgdydJg",
        "outputId": "7327ead0-90e4-46a9-a6f8-1ce440614867"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your OpenAI API key (starts with sk-): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "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\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O76wUJOo2e0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Register DejaVu font (robust fallback) - Need to work out what they use int the marking platform\n",
        "def register_dejavu_font():\n",
        "    candidates = [\n",
        "        \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
        "        \"/usr/share/fonts/truetype/DejaVu/DejaVuSans.ttf\",\n",
        "        \"/usr/share/fonts/truetype/freefont/FreeSans.ttf\",\n",
        "    ]\n",
        "    for p in candidates:\n",
        "        if os.path.exists(p):\n",
        "            pdfmetrics.registerFont(TTFont(\"DejaVuSans\", p))\n",
        "            return \"DejaVuSans\"\n",
        "    # fallback: download DejaVu\n",
        "    try:\n",
        "        url = \"https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans.ttf\"\n",
        "        local = \"/tmp/DejaVuSans.ttf\"\n",
        "        urllib.request.urlretrieve(url, local)\n",
        "        pdfmetrics.registerFont(TTFont(\"DejaVuSans\", local))\n",
        "        return \"DejaVuSans\"\n",
        "    except Exception:\n",
        "        # last resort, use builtin Helvetica (limited unicode)\n",
        "        return \"Helvetica\"\n",
        "\n",
        "BODY_FONT = register_dejavu_font()\n",
        "print(\"Using font:\", BODY_FONT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABAbRdd3yhi2",
        "outputId": "8ddecc50-6528-41e1-c985-34adeb0c9d5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using font: DejaVuSans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Utilities: render page, compress image, data URL\n",
        "def render_pdf_page_to_png(page: fitz.Page, dpi: int = 200) -> bytes:\n",
        "    zoom = dpi / 72.0\n",
        "    mat = fitz.Matrix(zoom, zoom)\n",
        "    pix = page.get_pixmap(matrix=mat, alpha=False)\n",
        "    return pix.tobytes(\"png\")\n",
        "\n",
        "def prepare_image_for_api(png_bytes: bytes, max_width: int = 1600, jpeg_quality: int = 75) -> str:\n",
        "    img = Image.open(io.BytesIO(png_bytes)).convert(\"RGB\")\n",
        "    if img.width > max_width:\n",
        "        new_h = int(max_width * img.height / img.width)\n",
        "        img = img.resize((max_width, new_h), Image.LANCZOS)\n",
        "    buff = io.BytesIO()\n",
        "    img.save(buff, format=\"JPEG\", quality=jpeg_quality, optimize=True)\n",
        "    b64 = base64.b64encode(buff.getvalue()).decode(\"utf-8\")\n",
        "    return f\"data:image/jpeg;base64,{b64}\""
      ],
      "metadata": {
        "id": "s4PWUO-bykDg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Robust Responses API call with fallback\n",
        "MODEL_CANDIDATES = [\"gpt-4o\", \"gpt-4o-mini\"]  # change if you have other vision models available\n",
        "def extract_text_from_response(resp) -> str:\n",
        "    # prefer .output_text\n",
        "    text = getattr(resp, \"output_text\", None)\n",
        "    if text:\n",
        "        return text.strip()\n",
        "    # attempt to parse .output list style\n",
        "    out = getattr(resp, \"output\", None)\n",
        "    if isinstance(out, list):\n",
        "        parts = []\n",
        "        for item in out:\n",
        "            if isinstance(item, dict):\n",
        "                c = item.get(\"content\") or item.get(\"text\") or item.get(\"message\")\n",
        "                if isinstance(c, str):\n",
        "                    parts.append(c)\n",
        "                elif isinstance(c, list):\n",
        "                    for sub in c:\n",
        "                        if isinstance(sub, dict) and sub.get(\"type\") == \"output_text\":\n",
        "                            parts.append(sub.get(\"text\", \"\"))\n",
        "        if parts:\n",
        "            return \"\\n\".join(parts).strip()\n",
        "    return f\"[OCR error: {repr(last_err)}]\"\n"
      ],
      "metadata": {
        "id": "AVE-qKtzyrC2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8A) This is the prompt wording...\n",
        "def ocr_image_with_openai(client: OpenAI, png_bytes: bytes, max_output_tokens: int = 4096) -> str:\n",
        "    data_url = prepare_image_for_api(png_bytes)\n",
        "    prompt = (\n",
        "        \"You are an OCR engine. Transcribe all readable text exactly. \"\n",
        "        \"Preserve line breaks and paragraphs. Do not add summaries, corrections, or commentary.\"\n",
        "        \"Look for small or faint writing.\"\n",
        "        \"Ignore pictures, emojis and symbols that can't be typed on a standard keyboard.\"\n",
        "    )\n",
        "    last_err = None\n",
        "    for model_name in MODEL_CANDIDATES:\n",
        "        try:\n",
        "            resp = client.responses.create(\n",
        "                model=model_name,\n",
        "                input=[{\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"input_text\", \"text\": prompt},\n",
        "                        {\"type\": \"input_image\", \"image_url\": data_url},\n",
        "                    ],\n",
        "                }],\n",
        "                temperature=0,\n",
        "                max_output_tokens=max(16, int(max_output_tokens)),\n",
        "            )\n",
        "            text = extract_text_from_response(resp)\n",
        "            if text:\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            # attempt chat completions fallback if available\n",
        "            try:\n",
        "                completion = client.chat.completions.create(\n",
        "                    model=model_name,\n",
        "                    messages=[\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": [\n",
        "                                {\"type\": \"text\", \"text\": prompt},\n",
        "                                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}},\n",
        "                            ],\n",
        "                        }\n",
        "                    ],\n",
        "                    temperature=0,\n",
        "                    max_tokens=2048,\n",
        "                )\n",
        "                content = completion.choices[0].message.content\n",
        "                if isinstance(content, str):\n",
        "                    return content.strip()\n",
        "            except Exception:\n",
        "                pass\n",
        "        time.sleep(1)\n",
        "    return f\"[OCR error: {repr(last_err)}]\"\n"
      ],
      "metadata": {
        "id": "bpxSTbvEyv5l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Clean transcript lines, with extra aggressiveness for pages 2 and 3 - this is th tex for removing a standard booklet print\n",
        "def clean_transcript_text(text: str, page_index: int = None) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    remove_phrases = {\n",
        "        \"WRITING\",\n",
        "        \"DO NOT WRITE OUTSIDE THE BORDER\",\n",
        "        \"END OF TEST\",\n",
        "        \"DO NOT WRITE OUTSIDE THE BOX\",\n",
        "        \"DO NOT WRITE OUTSIDE THE ANSWER AREA\",\n",
        "        \"DO NOT WRITE OUTSIDE THE MARGIN\",\n",
        "        \"START OF TEST\",\n",
        "    }\n",
        "    lines = text.splitlines()\n",
        "    cleaned_lines = []\n",
        "\n",
        "    # We will treat header/footer removal more aggressively for pages 2 and 3 (1-based)\n",
        "    aggressive = (page_index is not None and page_index in (2, 3))\n",
        "\n",
        "    for i, raw_line in enumerate(lines, start=1):\n",
        "        line = raw_line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        up = line.upper()\n",
        "\n",
        "        # exact phrase removal\n",
        "        if up in remove_phrases:\n",
        "            continue\n",
        "\n",
        "        # pure punctuation\n",
        "        if re.fullmatch(r'^[\\W_]+$', line):\n",
        "            continue\n",
        "\n",
        "        # numeric-only or digits with slashes/dashes/spaces: likely booklet codes\n",
        "        if re.fullmatch(r'^[\\d\\-\\s\\/]{1,12}$', line):\n",
        "            # Remove if aggressive, or if it appears in the first or last 6 lines\n",
        "            if aggressive or i <= 6 or (len(lines) - i) < 6:\n",
        "                continue\n",
        "\n",
        "        # common small booklet markers like a single digit on its own near header/footer\n",
        "        if aggressive and re.fullmatch(r'^\\d{1,2}$', line):\n",
        "            continue\n",
        "\n",
        "        # everything else, keep\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "    return \"\\n\".join(cleaned_lines).strip()"
      ],
      "metadata": {
        "id": "xITwgkBYzIBd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) Combine images for pages 1..3 into one stacked image - This is important step.\n",
        "def compose_combined_image(image_bytes_list: List[bytes], page_width: float, margin: float = 36, per_image_max_height: int = 2000) -> bytes:\n",
        "    imgs = [Image.open(io.BytesIO(b)).convert(\"RGB\") for b in image_bytes_list]\n",
        "    target_w = int(page_width - 2 * margin)\n",
        "    resized = []\n",
        "    for img in imgs:\n",
        "        w, h = img.size\n",
        "        ratio = target_w / w if w > 0 else 1.0\n",
        "        new_h = max(1, int(h * ratio))\n",
        "        if new_h > per_image_max_height:\n",
        "            scale = per_image_max_height / new_h\n",
        "            ratio *= scale\n",
        "            new_h = int(new_h * scale)\n",
        "        resized.append(img.resize((int(target_w), new_h), Image.LANCZOS))\n",
        "\n",
        "    total_h = sum(im.size[1] for im in resized)\n",
        "    combined = Image.new(\"RGB\", (target_w, total_h), color=(255, 255, 255))\n",
        "    y = 0\n",
        "    for im in resized:\n",
        "        combined.paste(im, (0, y))\n",
        "        y += im.size[1]\n",
        "    out = io.BytesIO()\n",
        "    combined.save(out, format=\"PNG\", optimize=True)\n",
        "    return out.getvalue()"
      ],
      "metadata": {
        "id": "2eN5Bl6AzX27"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11) Word-wrap helper for PDF - targeting in\n",
        "def wrap_text(text: str, font: str = BODY_FONT, size: int = 11, width: float = A4[0] - 72) -> List[str]:\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current = \"\"\n",
        "    for word in words:\n",
        "        candidate = f\"{current} {word}\".strip() if current else word\n",
        "        if stringWidth(candidate, font, size) <= width:\n",
        "            current = candidate\n",
        "        else:\n",
        "            if current:\n",
        "                lines.append(current)\n",
        "            if stringWidth(word, font, size) > width:\n",
        "                tmp = \"\"\n",
        "                for ch in word:\n",
        "                    if stringWidth(tmp + ch, font, size) <= width:\n",
        "                        tmp += ch\n",
        "                    else:\n",
        "                        lines.append(tmp)\n",
        "                        tmp = ch\n",
        "                current = tmp\n",
        "            else:\n",
        "                current = word\n",
        "    if current:\n",
        "        lines.append(current)\n",
        "    return lines"
      ],
      "metadata": {
        "id": "Dtxb-kKkzZoE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12) Build transcript PDF with first 3 pages combined - this is the details\n",
        "def build_transcript_pdf(original_images: List[bytes], transcripts: List[str], output_path: str, title: str):\n",
        "    page_width, page_height = A4\n",
        "    margin = 36\n",
        "    line_height = 14\n",
        "    c = canvas.Canvas(output_path, pagesize=A4)\n",
        "    c.setTitle(title)\n",
        "\n",
        "    # combine pages 1..3 if present\n",
        "    if original_images:\n",
        "        n_combine = min(3, len(original_images))\n",
        "        combined_img_bytes = compose_combined_image(original_images[:n_combine], page_width, margin=margin)\n",
        "        img = Image.open(io.BytesIO(combined_img_bytes))\n",
        "        iw, ih = img.size\n",
        "        ratio = min((page_width - 2 * margin) / iw, (page_height - 2 * margin) / ih)\n",
        "        dw, dh = iw * ratio, ih * ratio\n",
        "        x_pos = (page_width - dw) / 2\n",
        "        y_pos = (page_height - dh) / 2\n",
        "        c.setFont(BODY_FONT, 10)\n",
        "        c.drawString(margin, page_height - margin + 6, f\"{title} | original pages 1-{n_combine}\")\n",
        "        c.drawImage(ImageReader(io.BytesIO(combined_img_bytes)), x_pos, y_pos, dw, dh, preserveAspectRatio=True)\n",
        "        c.showPage()\n",
        "\n",
        "        for idx in range(n_combine, len(original_images)):\n",
        "            img_bytes = original_images[idx]\n",
        "            img = Image.open(io.BytesIO(img_bytes))\n",
        "            iw, ih = img.size\n",
        "            ratio = min((page_width - 2 * margin) / iw, (page_height - 2 * margin) / ih)\n",
        "            dw, dh = iw * ratio, ih * ratio\n",
        "            x_pos = (page_width - dw) / 2\n",
        "            y_pos = (page_height - dh) / 2\n",
        "            c.setFont(BODY_FONT, 10)\n",
        "            c.drawString(margin, page_height - margin + 6, f\"{title} | original page {idx+1}\")\n",
        "            c.drawImage(ImageReader(io.BytesIO(img_bytes)), x_pos, y_pos, dw, dh, preserveAspectRatio=True)\n",
        "            c.showPage()\n",
        "    else:\n",
        "        c.showPage()\n",
        "\n",
        "    # transcript section\n",
        "    c.setFont(BODY_FONT, 14)\n",
        "    c.drawString(margin, page_height - margin, \"Full transcript\")\n",
        "    y = page_height - margin - 24\n",
        "    c.setFont(BODY_FONT, 11)\n",
        "\n",
        "    # prepare combined transcripts: pages 1..3 combined as one block\n",
        "    combined_blocks = []\n",
        "    n_combine = min(3, len(transcripts))\n",
        "    if n_combine > 0:\n",
        "        t = \"\\n\".join(clean_transcript_text(transcripts[i], page_index=i+1) for i in range(n_combine))\n",
        "        combined_blocks.append((f\"[Pages 1-{n_combine}]\", t))\n",
        "    for i in range(n_combine, len(transcripts)):\n",
        "        header = f\"[Page {i+1}]\"\n",
        "        txt = clean_transcript_text(transcripts[i], page_index=i+1)\n",
        "        combined_blocks.append((header, txt))\n",
        "\n",
        "    for header, block in combined_blocks:\n",
        "        for chunk in [header, \"\"] + (block.splitlines() if block else []) + [\"\"]:\n",
        "            lines = [\"\"] if chunk == \"\" else wrap_text(chunk, BODY_FONT, 11)\n",
        "            for line in lines:\n",
        "                if y < margin:\n",
        "                    c.showPage()\n",
        "                    y = page_height - margin - 24\n",
        "                    c.setFont(BODY_FONT, 14)\n",
        "                    c.drawString(margin, page_height - margin, \"Full transcript (continued)\")\n",
        "                    c.setFont(BODY_FONT, 11)\n",
        "                c.drawString(margin, y, line)\n",
        "                y -= line_height\n",
        "\n",
        "    c.showPage()\n",
        "    c.save()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D0yWzSFzdy0",
        "outputId": "5b56fb96-f0b0-4b71-b34c-fef900768b8b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PDFs: 100%|██████████| 6/6 [04:15<00:00, 42.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Results saved to /content/drive/MyDrive/handwriting_outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 13) Main processing function - making it happen\n",
        "def process_pdfs(root_dir: str, output_dir: str, dpi: int = 180, pause: float = 0.45):\n",
        "    root = Path(root_dir)\n",
        "    out = Path(output_dir)\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "    pdf_paths = sorted(root.rglob(\"*.pdf\"))\n",
        "    if not pdf_paths:\n",
        "        print(f\"No PDFs found under {root}\")\n",
        "        return\n",
        "\n",
        "    rows = []\n",
        "    for pdf_path in tqdm(pdf_paths, desc=\"PDFs\"):\n",
        "        try:\n",
        "            doc = fitz.open(pdf_path)\n",
        "        except Exception as e:\n",
        "            print(\"Failed to open\", pdf_path, \":\", e)\n",
        "            continue\n",
        "\n",
        "        original_images = []\n",
        "        transcripts = []\n",
        "        for page_index in range(len(doc)):\n",
        "            page = doc.load_page(page_index)\n",
        "            png_bytes = render_pdf_page_to_png(page, dpi=dpi)\n",
        "            original_images.append(png_bytes)\n",
        "\n",
        "            try:\n",
        "                transcript = ocr_image_with_openai(client, png_bytes, max_output_tokens=4096)\n",
        "            except Exception as e:\n",
        "                transcript = f\"[OCR error: {repr(e)}]\"\n",
        "            transcripts.append(transcript)\n",
        "            time.sleep(pause)\n",
        "\n",
        "        # Save combined PDF (with pages 1..3 merged)\n",
        "        out_pdf = out / f\"{pdf_path.stem}__with_transcript.pdf\"\n",
        "        build_transcript_pdf(original_images, transcripts, str(out_pdf), title=pdf_path.name)\n",
        "\n",
        "        # Prepare Excel rows: combine pages 1..3 into one row labelled \"1-3\"\n",
        "        n_combine = min(3, len(transcripts))\n",
        "        if n_combine > 0:\n",
        "            combined_text = \"\\n\".join(clean_transcript_text(transcripts[i], page_index=i+1) for i in range(n_combine))\n",
        "            rows.append({\n",
        "                \"file_name\": pdf_path.name,\n",
        "                \"file_path\": str(pdf_path),\n",
        "                \"page_number\": f\"1-{n_combine}\",\n",
        "                \"transcript\": combined_text,\n",
        "            })\n",
        "        for i in range(n_combine, len(transcripts)):\n",
        "            cleaned = clean_transcript_text(transcripts[i], page_index=i+1)\n",
        "            rows.append({\n",
        "                \"file_name\": pdf_path.name,\n",
        "                \"file_path\": str(pdf_path),\n",
        "                \"page_number\": str(i+1),\n",
        "                \"transcript\": cleaned,\n",
        "            })\n",
        "\n",
        "        doc.close()\n",
        "\n",
        "    # write Excel\n",
        "    if rows:\n",
        "        df = pd.DataFrame(rows)\n",
        "        excel_path = out / \"handwriting_ocr_transcripts.xlsx\"\n",
        "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
        "            df.to_excel(writer, index=False, sheet_name=\"transcripts\")\n",
        "        print(\"Done. Results saved to\", out)\n",
        "    else:\n",
        "        print(\"No transcripts produced.\")\n"
      ],
      "metadata": {
        "id": "QV9cCmyPysi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 14) Run\n",
        "process_pdfs(DRIVE_FOLDER, OUTPUT_DIR, dpi=180, pause=0.45)"
      ],
      "metadata": {
        "id": "XzsjLL_-y3qj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}